
% \documentclass[10pt, psamsfonts, reqno]{amsart}
% \documentclass{article}

% IACR Transactions CLASS DOCUMENTATION
% Written by Gaetan Leurent gaetan.leurent@inria.fr (2016-2024)
%
% To the extent possible under law, the author(s) have dedicated all
% copyright and related and neighboring rights to this software to the
% public domain worldwide. This software is distributed without any
% warranty.
%
% You should have received a copy of the CC0 Public Domain Dedication
% along with this software. If not, see
% <http://creativecommons.org/publicdomain/zero/1.0/>.

\documentclass{iacrtrans}
\usepackage[utf8]{inputenc}
%-------Packages---------
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{appendix}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
%\usepackage[ruled,vlined,linesnumbered,resetcount,algo]{algorithm2e}
\usepackage{caption}
\usepackage{cryptocode}
\usepackage{yfonts,amsmath,amssymb,amsfonts}
\usetikzlibrary{arrows,positioning,calc}
% \usepackage{pdfpages}
% \usepackage{graphicx}
% \usepackage{mathabx} -> bad style
\usepackage[percent]{overpic}
% \usepackage{amssymb}
\usepackage{amsmath, amsthm, amssymb, thmtools}
\usepackage{scalerel}
\usepackage{stackengine}

\usepackage[british]{babel}

% margins
%\usepackage[left=3.95cm,right=3.95cm,bottom=3.6cm,top=3.6cm]{geometry}
\usepackage[left=3.80cm,right=3.80cm,bottom=3.70cm,top=3.70cm]{geometry}
%\usepackage[left=3.8cm,right=3.8cm,bottom=3.7cm,top=3.7cm]{geometry}
%\usepackage[
%	a4paper,hscale=0.65,vscale=0.75,marginratio=1:1,marginparwidth=2.7cm
%]{geometry}
%\usepackage[a4paper,left=2.54cm,right=2.54cm,bottom=2.54cm,top=2.54cm]{geometry}
%\usepackage[a4paper,left=3.8cm,right=3.8cm,bottom=3.8cm,top=3.8cm]{geometry}
%\usepackage[a4paper,left=3.7cm,right=3.7cm,bottom=3.7cm,top=3.7cm]{geometry}
%\usepackage[a4paper,left=3.6cm,right=3.6cm,bottom=3.6cm,top=3.6cm]{geometry}
%\usepackage[a4paper,left=3.7cm,right=3.7cm,bottom=3.7cm,top=3.7cm]{geometry}
%\usepackage[a4paper,left=3.4cm,right=3.4cm,bottom=3.4cm,top=3.4cm]{geometry}
%\usepackage[a4paper,left=3.2cm,right=3.2cm,bottom=3.2cm,top=3.2cm]{geometry}

% --------------------------

\author{Foteinos Mergoupis-Anagnou}
%\institute{GRNET, Athens, Greece, \email{fmerg@grnet.gr}}
\institute{Athens, Greece, \email{fmerg@grnet.gr}}
%\title[\texttt{iacrtans} class documentation]{Non-Interactive
%\\Schnorr Threshold Identification}
\title{Non-Interactive
\\Schnorr Threshold Identification}
%\subtitle{\LaTeX{} Class Documentation (v. 0.94)}

\begin{document}

\maketitle

% use optional argument because the \LaTeX command breaks the PDF keywords
%\keywords[\publname, ToSC, TCHES, LaTeX]{\publname{} \and ToSC
%  \and TCHES \and \LaTeX}

%\begin{abstract}
%  This document is a quick introduction to the \LaTeX{} class for the
%  \publname{}.
%\end{abstract}

%\tableofcontents{}

% algorithm style
\makeatletter
%\newcommand\fs@nobottomruled{
%  \def\@fs@cfont{\bfseries}
%  \let\@fs@capt\floatc@ruled
%  \def\@fs@pre{\hrule height.8pt depth0pt \kern2pt}%
%  \def\@fs@post{}% Formerly \def\@fs@post{\kern2pt\hrule\relax}%
%  \def\@fs@mid{\kern2pt\hrule\kern2pt}%
% \let\@fs@iftopcapt\iftrue
%}
\makeatother
%\floatstyle{nobottomruled}
\restylefloat{algorithm}

% Remove author from header
\pagestyle{plain}

\setlistdepth{9}

% \usepackage{cryptocode}

%--------Equations----------

%\setlength\abovedisplayskip{80pt}
%\setlength\belowdisplayskip{80pt}
%\setlength\abovedisplayshortskip{80pt}
%\setlength\belowdisplayshortskip{80pt}


%--------Theorem Environments--------
%theoremstyle{plain} --- default
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{con}[thm]{Construction}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}
\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}
%\newtheorem{lemma}[thm]{Lemma}
\newtheorem{Theorem}[thm]{Theorem}
\newtheorem{attack_game}[thm]{Game}
\newtheorem{protocol}[thm]{Protocol}
\newtheorem{scheme}[thm]{Scheme}

\theoremstyle{definition}
\newtheorem{rem}[thm]{Remark}
%\newtheorem{rem}{Remark}[Theorem]
\newtheorem{rems}[thm]{Remarks}
\newtheorem{warn}[thm]{Warning}
\newtheorem{sch}[thm]{Scholium}
\makeatletter
\let\c@equation\c@thm
\makeatother
\numberwithin{equation}{section}

% claim environment

%\newenvironment{claim}[1]{\par\noindent\underline{Claim:}\space#1}{}
%\newenvironment{claim}[1]{\par\noindent{\textit{Claim}:}\space#1}{}
%\newenvironment{claimproof}[1]{\par\noindent{\textit{Proof}:}\space#1}{\hfill $\blacksquare$}

% ----------------------------------------

% remove algorithm prefix
%\DeclareCaptionFormat{no_alg_prefix}{#3}
%\captionsetup[algorithm]{format=no_alg_prefix}

% "For" loop without "do"; "if" statement without "then"
\renewcommand\algorithmicthen{}
\renewcommand\algorithmicdo{}

%--------Meta Data: Fill in your info------
% \title{Threshold Non-Interactive Zero Knowledge}
% \title{Threshold Non-Interactive Zero-Knowledge Protocols}
% \title{Distributed Non-Interactive Schnorr Identification}
% \title{Threshold Schnorr Identification}
%\title{Non-Interactive \\Schnorr Threshold Identification}
% \title{Threshold Non-Interactive Schnorr Identification}
% \title{Non-Interactive Threshold Schnorr Identification}
% \title{Distributed Strictly Non-Interactive\\ Schnorr Identification}

%\author{Foteinos Mergoupis-Anagnou}
%\author{Author Name}

% \date{DEADLINES: Draft AUGUST 14 and Final version AUGUST 28, 2017}

%\begin{document}

\begin{abstract}
Threshold zero-knowledge protocols
have not been widely adopted,
presumably due to the relevant network overhead,
required infrastructure maintenance
and limited interoperability chances.
In this work, we propose an agile
threshold identification scheme based
on the Schnorr protocol.
Given a Shamir $(n, t)$-shared secret $x$, the proposed protocol allows
any $t^* \ge t$ (but no less) shareholders to collectively prove
that their secret keys combine to $x$ in the sense of interpolation
without revealing any information beyond that.
The protocol is both non-interactive and non-reliant
on the public shares.
On the one side, the provers do not need to engage
in any multi-party computation assisted by a trusted combiner,
sending their proof packets to the verifier directly.
On the other side, verification
contains no reference to the public shares,
meaning that packets are verified against
the group public key alone and the verifier does not need to
trust and register the individual members' identities.
The protocol can be cheaply adopted in
dynamic and unregulated environments,
where no certification processes or relevant infrastructure support
are available, and be seamlessly integrated
with existing verifiers by means of pure software extension.
No trusted setup is required beyond
the minimum assumption that the key has been
shared according to Shamir's secret sharing (or
equivalent DKG scheme)
and that the group public key has been advertised correctly;
in particular, the protocol is intended to be
secure against impersonation attacks
in the plain public-key model.
We provide evidence that this has good chances to
hold true by giving a formal security proof
in the random oracle model under the
one-more discrete-logarithm hardness (OMDL) assumption.

\end{abstract}

\maketitle

%\tableofcontents

\section{Introduction}

Distributing the prover of a zero-knowledge protocol
is usually achieved my means of a trusted combiner
who acts as group proxy.
The shareholders engage in some distributed computation
in order to produce a uniform commitment,
which they subsequently use to generate
ordinary proofs for their local shares.
After aggregating
the respective proof packets,
the proxy combines them into an ordinary proof
and forwards it to the verifier,
who proceeds to verification like in the non-distributed case.
That is, the combined proof lies in the domain of proofs
that could have been generated for the combined witness directly.
The idea is similar to that of the
Schnorr threshold signature scheme
\cite{paper_stinson_strobl}
and has been elaborated
in the proof-of-knoweldge context by \cite{paper_threshold_zk},
who apply it to distribute protocols as general as
proving the preimage of a homomorphism (\cite{paper_homomorphism}).

The integration of such protocols
is seamless on the verifier's side
because the latter does not need
to trust and register the shareholders' public keys.
However, this convenience comes at significant cost on the prover's side.
First and foremost, the distributed protocol
is highly interactive even though its non-distributed
counterpart may consist of a single communication step.
The multi-party computation
for the uniform commitment,
usually a distributed key generation (DKG) scheme,
introduces significant network overhead upon every protocol round
while also relying on subtle
security assumptions regarding the involved parties.
Note that delegating combination
to the verifier makes no difference
(except maybe for fewer trust assumptions)
because the protocol would remain equally interactive.
Techniques for reducing interactivity,
e.g., pseudorandom secret sharing, do not scale beyond
a limited number of provers and,
most importantly, require preprocessing
along with relevant infrastructure maintenance.
While the above may not be an issue
for operations with long-term impact
in monitored and regulated environments
(e.g., distributed signatures stored in a public ledger),
they become prohibiting if the provers
are compelled to act unattendedly and asynchronously
in the wild,
e.g., for the purpose of multi-factor authentication
or when performing some joint IoT or network operation
in order to rapidly release a sensitive action.
We are primarily interested for use cases of this kind.

Another relevant paradigm is that of threshold decryption,
which employs decoupled zero-knowledge proofs
in order to detect maliciously fabricated partial decryptors.
Given a ciphertext, the shareholders attach
a Chaum-Pedersen proof to their respective decryptor
in order to bound it securely to their respective key share.
After aggregating sufficiently many of these packets,
the decrypting party reconstructs the combined decryptor
only if the attached proofs verify against the respective
public shares, i.e., decryption is not released
unless all proofs are individually found to be valid.
Since every attached proof
includes an  embedded Schnorr proof for the respective shareholder's key,
one can eliminate the encryption specific details
in order to derive a pure identification protocol.

A protocol of this kind is non-interactive and requires
no infrastructure support or real-time communication on the provers' side,
allowing them to act independently; however,
it requires from the decrypting party (i.e., the verifier)
to have registered the correct public shares
in order to be able to individually verify the attached proofs.
This evidently entails the need for a trusted multi-key setup
that certifies both the ownership of the public shares
and their compatibility (i.e., that they
comprise a sharing of the group public key),
otherwise the protocol remains susceptible
to all sorts of rogue-key attacks.
Note that rogue-key attacks may not be a major issue
for threshold decryption because the attached
proofs are verified against both the respective public shares
and the given ciphertext; if the ciphertext has been generated
with respect to the correct public key,
a shareholder's rogue key will
most probably be detected. This is not so for the derived
identification protocol,
where the verification operation involves nothing
beyond the registered public shares.
In this case, security becomes
entirely dependent on the initial multi-key setup,
which has a generally intractable attack surface
and can only be analysed per use case.
Such a setup is not seamless to integrate with and,
if adopted, it comes at the cost of limited interoperability.
It is completely useless
in a dynamic and unregulated environment,
where the individual shareholders may change frequently or
no trust infrastructre can be assumed to be
in place at all.

\subsection{Contribution}\label{section_contribution}
The above discussion implies
that non-reliance on the public shares
and non-interactiveness on the provers' side appear to be
diametrically opposed properties;
eliminating infrastructure on one side
requires its existence and maintenance on the other.
We propose an infrastucture-free
Schnorr-based threshold identification scheme
that achieves non-interactiveness \textit{and} non-reliance;
as such, it is suitable for flexible identification
settings and can be cheaply adopted
in the following sense: (a) existing verifiers
need only extend their software
in order to support the distributed case,
without adding infrastructure
for trusting and registering
public shares (b) existing keys
can be shared at the verifiers' complete negligence.
No trusted setup is required beyond
the minimum assumption that a key has been
shared amongst a group of shareholders according to some
Shamir-based scheme (no matter which)
and that the combined public key has been advertised
correctly; in particular,
the protocol should be secure against
impersonation attacks in the plain public-key model
(\cite{paper_bellare_musig}).
We provide evidence that this has good chances to be true
by demonstrating a formal security proof in the random oracle model
under the one-more discrete-logarithm hardness (OMDL) assumption.


\subsection{Organization}\label{section_organization}
In Section \ref{section_problem}, we get a closer look
at distributed Schnorr identification
and argue in detail why certain solutions
fail to meet its pragmatic needs,
specifically with respect to
dynamic, unregulated and decentralized environments.
In Section \ref{section_orst}, we introduce the
proposed threshold identification scheme
and make some high-level security considerations,
including a key-recovery attack against
its interactive variance.
In Section \ref{section_security_notions},
we specify the threat model
and derive the relevant attack games.
We do not formulate auxiliary notions
for zero-knowledge protocols
(e.g., soundness, HVZK,
witness indistinguishability etc.)
in the threshold setting,
focusing directly on security against impersonation attacks;
however, we do derive a restricted notion of extractability
(in the sense of special soundness)
in order to specify a reasonable attack model
under the OMDL hardness assumption.
In Section \ref{section_security_proof} we present
the formal security proof in the random oracle model,
employing the above mentioned key-recovery attack.
The main facts regarding Shamir's secret sharing
are presented in Appendix \ref{section_shamir}
and a quick refresher on the
Schnorr protocol can be found below.

\subsection{Schnorr identification}\label{section_schnorr}

\noindent
Fix a cyclic group $\mathbb{G} = \langle g \rangle$ of order $q$.
A secret key is a scalar $x \in \mathbb{Z}_q$,
with the group element $y = g ^ x$
being its public counterpart;
equivalently, $x = \log\hspace{1pt} y$,
where the logarithm is taken with respect to a fixed
generator $g$ of the underlying group structure.
\textit{Discrete-logarithm hardness \textup{($\mathsf{DL}$)}} for
the system under consideration
is the assumption that computing the logarithm of
a uniformly random element is infeasible
for every existing computer.
More accurately, given $y \leftarrow_\$ \mathbb{G}$,
every probabilistic polynomial-time algorithm
should correctly compute $x \leftarrow \log\hspace{1pt} y$
with negligible chance of success,
where negligibility is determined by
the current level of disposable computational power.
Industrial public-key cryptography relies increasingly more
on the plausibility of this assumption over
carefully chosen groups, a trend that will
only be challenged with the advent of practical quantum computing.

The \textit{Schnorr protocol}
is a non-interactive zero-knowledge (NIZK) scheme,
allowing the key holder of $y = g ^ x$
to prove knowledge of $x$
without revealing any information about the latter.
Its original interactive variance \cite{paper_schnorr} is a sigma protocol.
The prover samples $r \leftarrow_\$ \mathbb{Z}_q$,
stores it for the current session
and sends the commitment $u \leftarrow g ^ r$ to the verifier.
The verifier samples a challenge $c \leftarrow_\$ \mathbb{Z}_q$,
caches it for the current session and sends it to the prover.
Finally, the prover responds with $s = r + c\hspace{1pt}x$
and the verifier accepts only if the relation
\vspace{5pt}
\begin{equation*}
g ^ s = y ^ c\hspace{1pt}u
\vspace{5pt}
\end{equation*}
is satisfied; indeed,
$g^s=g^{r + c\hspace{1pt}x}
=(g^{\hspace{1pt}x})^c\hspace{1pt}g^r
=y^c\hspace{1pt}u$.
In the presence of a secure hash function
$H: \mathbb{G} \rightarrow \mathbb{Z}_q$,
the protocol can be made non-interactive (1-step)
by means of the Fiat-Shamir transform. Specifically,
the prover precomputes $c \leftarrow H(u)$
and sends $(u, s)$ to the verifier,
who retrieves $c$ from $u$ and proceeds
to verification.
Non-interactiveness is most often preferrable
due to greater robustness, reduced bandwidth usage
and non-reliance on real-time communication.
The intuition behind is that a secure hash function
should inject sufficiently high entropy
across every bit of its output,
so that assigning $c \leftarrow H(u)$
becomes indistinguishable from sampling $c$ uniformly at random.
The current mainstream formalizes this fact
within the random oracle model (ROM).

The Schnorr protocol is an identification scheme
because it verifies the holder of a key
against its public counterpart in a sound and complete fashion.
Key semantics are not essential;
the protocol identifies any procedure
that ``sees" the secret logarithm of some given group element.
It is namely a zero-knowledge (ZK) proof-of-knowledge primitive
for the discrete logarithm and as such applicable in any context where this knowledge arises as crucial
(e.g., in plain ElGamal encryption,
where a proof of randomness
may be attached in order to derive a non-malleable ciphertext);
most notably, it is the building block
for proving knowledge of witnesses to arbitrary linear relations,
common instances of which are
the Chaum-Pedersen protocol for Diffie-Hellman tuples
and the Okamoto protocol for representations.
From this perspective,
security against impersonation attacks
amounts to the infeasibility of fabricating
a proof that verifies against a group element
without knowing its logarithm;
in the zero-knowledge setting,
this property is formalised as witness extractability
under discrete-logarithm hardness.
The protocol becomes meaningful
only in the font of $\mathsf{DL}$ hardness,
which in turn guarantees
that the protocol is secure.\footnote{The
most far-reaching result of this kind is
security against active and concurrent impersonation attacks
under ``one-more" discrecte logarithm (OMDL) hardness;
cf. Theorem 2, \cite{paper_bellare_palacio}.}

\section{The problem of distributed Schnorr identification}\label{section_problem}

Suppose that some secret $x$
with public counterpart $y$ is distributed as $x_1, \dots, x_n$
among $n$ shareholders by means of Shamir's $(n, t)$-sharing
or equivalent distributed key generation (DKG)
protocol. That is, it shouldn't matter if $x$ is shared by
a dealer or is implicitly defined in a decentralized
fashion without being locally reconstructible;
it only suffices that the output of the
distribution scheme is indistinguishable
from that of Shamir's secret sharing.
We are interested for a protocol that allows any
$t^* \ge t$ (but no less) parties to collectively prove
that they belong to the group represented by $y$
in a zero-knowledge fashion. More accurately, involved shareholders
should be able to prove that their shares
combine to $x$ in the sense of interpolation
(cf. Remark \ref{shamir_reconstruction})
without revealing any information beyond that;
evidently, this reduces to ordinary Schnorr identification
for the edge case $t=1$.
Security against impersonation attacks should roughly mean that any
efficient adversary controlling up to $t-1$ shareholders
remains unable to fabricate a proof that verifies
with non-negligible chances.
We obviously ask for the protocol to be
as less interactive as possible;
in the ideal case, involved provers should not need to
engage in any communication rounds, performing single and
independent requests to the verifier.

There is a seemingly trivial solution to this problem
involving the public keys
$y_i = g ^ {x_i},\hspace{2pt} 1 \le i \le n,$
of the shareholders.
Let $Q \subset \{1, \dots, n\}$
be a coalition of shareholders that engage in
an identification session with a verifier.
The $i$-th party generates
an ordinary Schnorr proof
for its respective share, i.e.,
\vspace{5pt}
\begin{equation*}
(u_i, s_i),
\ \ s_i \leftarrow r_i + c_i x_i,
\ \ c_i \leftarrow H(u_i),
\ \ u_i \leftarrow g ^ {r_i},
\ \ r_i \leftarrow_\$ \mathbb{Z}_q
\vspace{5pt}
\end{equation*}
and sends it to the verifier.
After aggregating the proof packets
$(u_i, s_i),\hspace{2pt}i \in Q,$
the verifier computes
$c_i \leftarrow H(u_i),\hspace{2pt} i \in Q,$
and accepts only if the relation
\vspace{5pt}
\begin{equation}\label{intro_trivial_verification_1}
y = \prod_{i \in Q} y_i ^{\lambda_i}
\hspace{2.50pt}
\land
\hspace{3pt}
g ^ {s_i} = y_i ^ {c_i} u_i,
\hspace{2pt}
\forall i \in Q
\vspace{5pt}
\end{equation}
is satisfied, where $\{\lambda_i\}_{i \in Q}$ are the
Lagrange interpolation coefficients for $Q$.
We will refer to this protocol as the \textit{trivial approach}.
The verifier identifies the involved parties only if
their public shares combine to the group public key
and they individually prove knowledge of their respective secrets.
The first condition is satisfied only if $|Q| \ge t$ (as desired)
while the second is a method for hardening
distributed protocols against malleability, i.e.,
requiring from the involved parties
to present contextual proofs-of-knowledge
that verify against their respective public keys.
Note also that \eqref{intro_trivial_verification_1} is an overkill.
If the public shares $y_1, \dots, y_n$
must be advertised and trusted anyway,
i.e., the verifier registers them as the fixed sharing of $y$,
the identifying condition reduces to
\vspace{5pt}
\begin{equation}\label{intro_trivial_verification_2}
|Q| \ge t
\hspace{3.50pt}
\land
\hspace{3pt}
g ^ {s_i} = y_i ^ {c_i} u_i,
\hspace{2pt}
\forall i \in Q
\hspace{1pt}.
\vspace{5pt}
\end{equation}
\noindent
The protocol is secure
if $y_1, \dots, y_n$ is the correct $(n, t)$-sharing of $y$;
however, in the absence of side input
on the verifier's side,
its security relies entirely on the registration process.
Indeed, as illustrated by \eqref{intro_trivial_verification_2},
the bulk of the work has been
absorbed in the registration phase;
the verifier accepts only because
the public shares have already been trusted
and the security analysis
reduces trivially to the threat model for the initial setup.
The problem is that
a trusted multi-key setup is itself
a highly non-trivial assumption,
since the possibilities regarding
roles and operations
compose a rather broad attack surface.
In the best case, a proxy that is responsible
for advertising the public shares
may tamper with a certain subset of them,
causing denial-of-service whenever
the respective shareholders engage
in a session.
Or, worse, the malicious proxy colludes with
a registry delivering the group public key
and becomes capable of mounting a wide range of rogue-key attacks.
While ad hoc threat models can obviously be formulated
for specific use cases (e.g., for a restricted pool of
shareholders that undergo a well specified certification process),
this discussion implies that
an ecompassing threat model is impossible to pin down.
In the terminology of Bellare and Neven \cite{paper_bellare_musig},
the protocol cannot be proven secure
in the \textit{plain public-key} model.

One can alleviate the situation by working in the
\textit{knowledge of secret key} (KOSK) model,
i.e., design a zero-knowledge based registration process,
capable of detecting rogue-key attempts
by means of purely cryptographic techniques.
In this case, a security analysis becomes more tractable
because a threat model for the initial setup can be
formulated in terms of well defined malicious acts.
However, an operation of this kind is not obvious to scale
and its repetition can become cumbersome
if the shareholders are not static.
More importantly, KOSK narrows
the applicability of the protocol severely,
since any verifiable registration process
is an infrastructure plugin that real-world vendors
may be unable or unwilling to interoperate with.

These are standard arguments speaking in favour
of secure multi-party protocols that are agnostic
with respect to their setup internals.
For threshold identification,
this requirement is further hardened as
\textit{non-reliance on the public shares},
meaning that the verification operation should only involve
the group public key.
In fact, this is a sine qua non if the desired protocol is
to be applicable in unregulated decentralized settings.


\subsection{Distributed provers in decentralized networks}\label{section_distributed_provers}

We contended above that non-reliance on the public shares
is a necessary condition for pragmatic security
in the plain public-key model, where
no concrete certification process
for the public shares can be assumed
to be available or known.
Existence of such processes indicates
a relatively limited number of shareholders
that either belong to an organization or participate
in a supposedly decentralized network,
where group constitution is subject to
regulation and monitoring.
In such cases,
the role of verifier is usually reserved for
a bunch of authorized servers or nodes,
responsible for managing some protected resource or
performing specific acts in the context of a broader protocol.
The trivial approach with an ad hoc setup,
supported by the relevant infrastructure
and threat moel,
can be a decent solution,
at least insofar as the group of shareholders
remains relatively static
and general interoperability
is not a hard requirement.
We are interested for use cases beyond that.

We address distributed identification in
a fairly unconditioned context,
with as few assumptions as possible
beyond a generic network
with reliable packet delivery.
The only assumption regarding
group constitution is that
the combined public key
be correctly advertised.
No infrastructure is
assumed to be available after that phase,
e.g., proxies, registries for individual member identities,
storages for pre-processed quantities,
aggregators interacting with involved provers,
or even traceable communication channels between them.
A group might be created on the fly and its public key
be the only public remnant of that ceremony;
after dissolution of the setup channels,
its members may have no way to coordinate or identify
with each other, be unwilling to do so or be compelled to
act independently.

Absence of infrastructure implies that
the provers should be able to
act without real-time communication,
i.e., the protocol should be
non-interactive on their side.
This introduces a high degree of asynchronicity
which imposes constraints on their interaction
with the verifier.
In particular, a verifier's response
to the $j$-th shareholder should not be dependent
on any request from the $i$-th shareholder for $i \neq j$.
Equivalently, the proving session should decouple into
independent interactions between the verifier
and the involved provers.
Ideally, the decoupled interactions should themselves be
non-interactive, i.e., consist of a single communication
step in which the involved parties send their respective
proofs to the verifier.

On the verifier's side, absence of infrastructure
implies non-reliance on the public shares.
Consider the extreme case of a
truly decentralized network,
where qualified verifiers can be user devices
or application servers alike in a dynamic fashion.
That is, verification can occur
on a multitude of devices that are not aware
of the individual members' identities for every group
they come accross in the network.
It simply cannot be expected from a mobile or IoT device
to maintain the public shares for every group
it might want to identify,
let alone engage in a certification process
in order to register them.
Note also that fetching the public shares
from remote registries is not an option;
even if such registries exist,
trusting them is a highly non-trivial assumption
(comparable to KOSK)
and depending on them would significantly affect
latency and robustness.

Further efficiency considerations are here in order,
since the decentralized verifiers do not necessarily possess
the capabilities of a fine-tuned application server.
It is well known that the wireless transmission
of a single bit requires more power
than a 64-bit (or 32-bit) instruction by orders of magnitude,
implying that packet size is
the dominant factor with respect to overall energy consumption;
from the individual node's perspective,
this amounts to shorter battery life
if it runs on a wireless device.
Reduced bandwidth usage is even more important
in order to avoid network congestion,
since the proof packets have to be massively trasmitted
through relay nodes
in order to be verified at arbitrary locations.
The problem remains to
design an efficient and non-interactive threshold protocol
that is non-reliant on public shares, infrastructure-free
on both sides, secure in the plain public-key model,
and as such applicable in truly decentralized settings.



\subsection{Non-working solutions}\label{section_non_working_solutions}

We discuss two plausible approaches to the
problem of threshold identification
and show how they fail to meet
the above requirements.
Both are within the plain public-key model.

\subsubsection{Uniform commitment approach}\label{section_uniform_commitment}

Recall that Schnorr signature is
Schnorr identification with a message baked
into the hash function.
This suggests an approach similar to the
threshold signature scheme introduced
by \cite{paper_stinson_strobl}.
Let $x_1, \dots, x_n$ be the fixed
$(n,t)$-sharing of $x$ and $y = g ^ x$ be its public counterpart.
A coalition of shareholders $Q \subset \{1, \dots, n\}$
execute some DKG protocol to generate
\vspace{5pt}
\begin{equation*}
r = \sum_{i \in Q} \lambda_i r_i,
\vspace{5pt}
\end{equation*}
where $\{\lambda_i\}_{i \in Q}$
are the interpolation coefficients
for $Q$, holding the respective $r_i$'s in private.
$r$ need not be locally reconstructible
but the provers should be able to
infer the distributed commitment
$u \equiv g^r$ at the end of the process.
Next, the involved parties generate Schnorr proofs
using the respective commitment shares with uniform challenge $H(u)$, i.e.,
\vspace{5pt}
\begin{equation*}
(u_i, s_i),
\ \ s_i \leftarrow r_i + c\hspace{1pt}x_i,
\ \ u_i \leftarrow g ^ {r_i},
\ \ c \leftarrow H(u)
\hspace{1pt},
\vspace{5pt}
\end{equation*}
and send them to the verifier. 
After aggregating $(u_i, s_i)$, $i \in Q$,
the verifier computes
\vspace{5pt}
\begin{equation*}
s \leftarrow \sum_{i \in Q} \lambda_i s_i,
\ \ c \leftarrow H(u),
\ \ u \leftarrow \prod_{i \in Q} u_i ^ {\lambda_i}
\vspace{5pt}
\end{equation*}
and accepts only if the relation
$g ^ s = y ^ c u$ is satisfied.
Indeed, if $|Q| \ge t$,
twofold application of Shamir's reconstruction formula yields
\vspace{5pt}
\begin{equation*}
g ^ s =
\prod_{i \in Q} \big(g ^ {s_i}\big)^{\lambda_i} =
\Big(\prod_{i \in Q}\big(g ^ {x_i}\big)^c\Big)^{\lambda_i} \prod_{i \in Q}\big(g ^ {r_i}\big) ^ {\lambda_i} =
\Big(\prod_{i \in Q}y_i^{\lambda_i}\Big)^c \prod_{i \in Q}u_i^{\lambda_i}=
y^c u.
\vspace{5pt}
\end{equation*}
Verification requires $|Q|\hspace{1pt} +\hspace{1pt} 2$
exponentations and the inbound throughput grows linearly
with respect to $|Q|$; for example,
taking $\mathbb{G}$ to be the elliptic curve P256
and assuming that 128-bit challenges is sufficient to work with,
this is $512 \hspace{1pt} |Q|$ bits per protocol
round. If accomodated, we can offload the computation of $s$ and $u$
to a semi-trusted combiner,
who acts as group proxy by forwarding $(u, s)$ to the verifier;
in this case, the verifier coincides with that of the
non-distributed case and its performance
is not dependent on the number of involved shareholders.
This is usually the case for Schnorr threshold signatures.

This protocol is equivalent to ordinary Schnorr identification
if we treat the involved provers as a single entity;
i.e., $(u, s)$ lies in the domain
of proofs that could have been generated
for $x$ directly.
This commutation is crucial for
a threshold signature scheme,
where the final output may need to
remain available in the long run
and consequently use minimum space,
but not for an identification protocol,
where no persistent data are generated.
In fact, it countervenes the requirement
of reduced interactiveness, as it is achieved through
the distributed computation of $u$.
This introduces significant
network overhead upon every protocol round and
presupposes that some infrastructure is available
to the shareholders.
Consequently, despite the efficiency of its verifier,
the uniform commitment approach does not meet the requirements
of Section \ref{section_distributed_provers} on the provers' side.
The state-of-the-art for managing the network overhead
of Schnorr threshold signatures
is the FROST protocol introduced by \cite{paper_frost}
and its variants.
This reduces the number of communication rounds
to one or two by means of a semi-trusted aggregator,
depending on whether
a preprocessing stage takes place during the initial setup;
however, it comes at the cost of more
infrastructure (and more trust assumptions)
which makes it even more
prohibiting for a flexible identification setting.

\subsubsection{Completely decoupled approach}\label{section_decoupled_commitment}

This is a variance of the trivial approach,
where the public shares
need not be advertised.
Instead, they are attached to the proofs.
Given a $(n, t)$-sharing
$x_1, \dots, x_n$ of some secret $x$
with public counterpart $y$,
a coalition of shareholders
$Q \subset \{1, \dots, n\}$
generate
\vspace{5pt}
\begin{equation*}
(y_i, u_i, s_i),
\ \ y_i \leftarrow g ^ {x_i},
\ \ s_i \leftarrow r_i + c_i x_i,
\ \ c_i \leftarrow H(u_i),
\ \ u_i \leftarrow g ^ {r_i},
\ \ r_i \leftarrow_\$ \mathbb{Z}_q
\vspace{5pt}
\end{equation*}
respectively
and send them to the verifier.
After aggregating
$(y_i, u_i, s_i)$, $i \in Q$,
the verifier computes $c_i \leftarrow H(u_i),\hspace{2pt} i \in Q,$
and accepts only if condition
\eqref{intro_trivial_verification_1}
is satisfied.
Security reduces to the proof-of-knowledge
property of the Schnorr protocol.
Every party ``should know''
the logarithm of the attached group element
because the respective proof verifies;
since the attachments combine to $y = g ^ x$,
the respective secret logarithms comprise a sharing of
$x$ and the provers should belong to the group
represented by $y$.

The protocol is non-reliant on public shares and
infrastructure-free on both sides.
However, it requires
$3\hspace{1pt}|Q|$ exponentiations per verification
and at least $33\%$ increased bandwidth usage
as compared to the trivial approach.
While this regression might be insignificant
for a central identifying server
with even several thousands of users,
it can badly affect efficiency under
the energy intensive and
highly congested network conditions
of true decentralization
(cf. Section \ref{section_distributed_provers}).

Moreover, while the protocol is most probably secure,
the security argument is not as strong
as it might seem. Recall that the Schnorr proof-of-knowledge
property is not defined in terms of an attack game
and it basically means extractability under $\mathsf{DL}$
hardness. Consequently, the security of the threshold protocol
cannot reduce to it strictly;
by saying that it reduces to it,
what we actually mean is that
some relevant extraction procedure
should itself be reproducible in the context of
a rewindable black-box threshold attack
against its interactive variance.
This does not seem to be possible.
Consider an adversary $\mathcal{A}$ who knows
$\{x_i\}_{i \in J}$
for some $J \subset \{1, \dots, n\}$ with $|J| = t - 1$
and wants to impersonate
$Q = J \cup \{\hspace{1pt}j\hspace{1pt}\}$
with $j \not \in J$ against an interactive verifier.
The extractability argument regarding security
means that any such $\mathcal{A}$
should necessarily spit $x_j$ in case of
a successful impersonation attack by rewinding.
One possible attack pattern could
be using the shares that are known to $\mathcal{A}$ directly.
That is, for every $i \in J$,
$\mathcal{A}$ sends
\vspace{5pt}
\begin{equation*}
(y_i, u_i),
\ \ y_i \leftarrow g ^ {x_i},
\ \ u_i \leftarrow g ^ {r_i},
\ \ r_i \leftarrow_\$ \mathbb{Z}_q
\vspace{5pt}
\end{equation*}
to the verifier,
who samples $c_i \leftarrow_\$ \mathbb{Z}_q$
for $u_i$
and sends it to $\mathcal{A}$;
in turn, $\mathcal{A}$ responds
with $s_i \leftarrow r_i + c_i\hspace{1pt}x_i$.
Next, $\mathcal{A}$ fabricates $u_j$
accoridng to some black-box strategy and sends
$(y_j, u_j),\hspace{2pt} y_j \equiv g ^ {x_j},$ to the verifier,
who samples $c_j \leftarrow_\$ \mathbb{Z}_q$ for $u_j$
and sends it to the adversary.
Finally, $\mathcal{A}$ fabricates $s_j$
according to some black-box strategy
and sends it to the verifier.
Evidently, extraction of $x_j$ is here possible
by rewinding $\mathcal{A}$
exactly before sending $(y_j, u_j)$ to the verifier
(provided that it
succeeds in generating a valid transcript).
This is ordinary extraction
embedded into a decoupled attack pattern.
However, a black-box threshold attack
is far from confined to this pattern.
Since $y$ admits many possible sharings,
$\mathcal{A}$ could possibly fabricate attachments
that do not coincide with the fixed public shares
and still combine to the group public key;
in this case, rewinding $\mathcal{A}$ at any location
would fail to yield $x_j$.
We would need the decoupled proofs to
be junct into a single verifying operation
in order for the extraction of $x_j$
to be possible by rewinding.

\section{One-Round Schnorr Threshold Identification}\label{section_orst}

\noindent
We fix a cyclic group $\mathbb{G} = \langle g \rangle$ of order $q$
where the $\mathsf{DL}$ problem is hard and
a secure hash function $H: \mathbb{G} \rightarrow \mathbb{Z}_q$.
Shamir's secret sharing is denoted by $D$
(cf. Appendix \ref{section_shamir}) and the values
of its parameters are inferred always from context.

\subsection{The $\mathsf{ORST}$ protocol}

Given integers $(n, t)$ such that $1 \le t \le n < q$,
we define the following scheme.

\begin{protocol}\label{orst_protocol}
($
\mathsf{ORST}
	_{\hspace{1pt}\mathbb{G},\hspace{0.5pt} n,\hspace{0.5pt} t}
$
-- \textit{One-Round Schnorr $(n, t)$-Threshold Identification})
\enumerate[label=$\circ$, leftmargin=17pt]
\vspace{2pt}
\item \textit{Setup}. Some uniformly random secret is
distributed among a group of $n$ shareholders
by means of Shamir's $(n, t)$-sharing, i.e.,
\vspace{5pt}
\begin{equation*}\label{orst_sharing}
(x_1, \dots, x_n;\hspace{2pt} y) \leftarrow D(x),
\hspace{4pt} x \leftarrow_\$ \mathbb{Z}_q
\vspace{5pt}
\end{equation*}
The threshold parameter and the public shares may remain private to the group,
who needs only advertise the combined public key $y$.
\vspace{5pt}
\item \textit{Proving phase}. A coalition of shareholders
$Q \subset \{1, \dots, n\}$ generate
\vspace{5pt}
\begin{equation*}
(u_i, s_i),
\ \ s_i \leftarrow r_i + c_i\hspace{1pt} x_i,
\ \ c_i \leftarrow H(u_i),
\ \ u_i \leftarrow g ^ {r_i},
\ \ r_i \leftarrow_\$ \mathbb{Z}_q
\vspace{5pt}
\end{equation*}
respectively and send them to the verifier,
holding the respective $r_i$ in private, $i \in Q$.
\vspace{5pt}
\item \textit{Verification}.
After aggregating $(u_i, s_i),\hspace{2pt} i \in Q,$
the verifier accepts only if
\vspace{6pt}
\begin{equation}\label{orst_verification_0}
\exp\Big(\hspace{1pt}g, \sum_{i \in Q} \mu_i s_i\Big) =
y^{\bar{c}} \prod_{i \in Q} u_i ^ {\mu_i},
\vspace{-3pt}
\end{equation}
where
\vspace{2pt}
\begin{equation}\label{orst_aliases}
\bar{c} \leftarrow \prod_{i \in Q} c_i,
\ \ \  \mu_i \leftarrow \lambda_i \prod_{j \in Q \setminus \{i\}} c_j,
\ \ \  c_i \leftarrow H(u_i)
\vspace{8pt}
\end{equation}
and $\{\lambda_i\}_{i \in Q }$ are the
Lagrange interpolation coefficients for $Q$.
\vspace{5pt}
\end{protocol}

\noindent
The sharing scheme of the setup phase may be replaced
with any DKG whose output distribution
is indistinguishable from that of Shamir's secret sharing.
That is, it shouldn't matter if $x$ has been shared by a dealer
or it cannot be reconstructed at a single location; it only
suffices that the correct public key
$y = g ^ x$ be advertised at the end of the process.
Note that DKG schemes usually assume a bound $0 \le l < t$
on the number of corrupt parties
in order for the distribution to be secure,
but this does not affect the security analysis of
$\mathsf{ORST}$
(cf. Section \ref{section_general_threat_model})
because it belongs to the threat model of the
specific use case.

During the proving phase,
the involved shareholders generate ordinary Schnorr
proofs for their secret shares
and send them to the verifier asynchronously.
No real-time communication is required between them.
Order coordination or some session timeout
may be enforced by the verifier for the needs of a specific use case,
but this should not affect the threat model
because the local computations remain decoupled.
The protocol is non-interactive in a strict sense
(``one-round'') and meets the requirements of
Section \ref{section_distributed_provers} on the provers' side.

Verification efficiency is comparable to that of the uniform
commitment approach (Section \ref{section_uniform_commitment}),
if at the cost of more (non-exponential) numerical operations.
It requires $|Q| + 2$ exponentiations
and the inbound throughput grows linearly
with respect to the number of involved shareholders;
for example, if $\mathbb{G}$ is the elliptic curve P256 and
128-bit challenges is sufficient to work with,
this is $512 \hspace{1pt} |Q|$ bits per protocol round.
Since the operation per se involves
the group public key alone, no registration of public shares is
required and the protocol meets
the requirements of Section \ref{section_distributed_provers}
on the verifier's side.
Existing verifiers need only extend
their software in order to support the distributed case,
without adding new infrastructure
for trusting and registering any public shares.

\begin{rem}\label{rem_orst_verification_exponents}
(\textit{Validity condition})
By equating exponents,
\eqref{orst_verification_0} translates to
\vspace{5pt}
\begin{equation}\label{orst_verification_exponents}
\sum_{i \in Q} \mu_i\hspace{1pt} (s_i - r_i) =
\bar{c} \cdot x\hspace{1pt},
\vspace{5pt}
\end{equation}
where $r_i \equiv \log u_i$.
Observe that this contains no reference to secret shares.
\end{rem}

\begin{rem}\label{orst_correctness}
(\textit{Correctness})
Let $y_i = g ^ {x_i},\hspace{2pt} 1 \le i \le n$
be the public shares.
Under this notation,
the left-hand side of condition \eqref{orst_verification_0}
transforms as
\vspace{5pt}
\begin{equation*}
\prod_{i \in Q} \big(g ^ {s_i }\big) ^ {\mu_i} =
\prod_{i \in Q} \big(g ^ {x_i}\big) ^ {c_i \mu_i} \big(g ^ {r_i}\big) ^ {\mu_i} =
\prod_{i \in Q} \big(g ^ {x_i}\big) ^ {\lambda_i \bar{c}} \prod_{i \in Q} \big(g_i ^ {r_i}\big) ^ {\mu_i} =
\Big(\prod_{i \in Q} y_i ^ {\lambda_i}\Big) ^ {\bar{c}} \prod_{i \in Q} u_i ^ {\mu_i},
\vspace{5pt}
\end{equation*}
which yields the right-hand side if (and only if) $|Q| \ge t$.
In other words, the proper execution of the protocol verifies
only if at least $t$ shareholders are involved.
\end{rem}

\begin{rem}\label{orst_interactive}
(\textit{Interactive variance})
We may regard $H$ as
a random oracle as long as predicting any of its output bits
is infeasible. Equivalently, the provers send their commitments
to the verifier, who lazily samples challenges
by maintaining a lookup table $\mathsf{Map}$ per session.
For every $i \in Q$, the $i$-th shareholder
samples $r_i \leftarrow_\$ \mathbb{Z}_q$
and sends
$u_i = g ^ {r_i}$ to the verifier.
If $u_i \not \in \textup{Dom}(\mathsf{Map})$,
the verifier samples
$c_i \leftarrow_\$ \mathbb{Z}_q$
and caches
$\mathsf{Map}\hspace{0.5pt}
[\hspace{0.5pt}u_i\hspace{0.5pt}]\leftarrow c_i$;
in either case, it sends %the challenge
$c_i \leftarrow \mathsf{Map}\hspace{0.5pt}
[\hspace{0.5pt}u_i\hspace{0.5pt}]$
to the shareholder, who responds with
$s_i \leftarrow r_i + c_i\hspace{1pt}x_i$.
After aggregating
$s_i,\hspace{2pt} i \in Q,$
the verifier checks
\eqref{orst_verification_0} using
the previously cached challenges
$c_i = \mathsf{Map}\hspace{0.5pt}
[\hspace{0.5pt}u_i\hspace{0.5pt}],\hspace{2pt} i \in Q$.
\end{rem}

%\noindent
%We proceed to the formal definitions regarding $\mathsf{ORST}$.

\begin{defn}\label{orst_weights_definition}
The \textit{weights of}
$\{u_i\}_{i \in Q} \subset \mathbb{G}$
are the scalars
$\{\mu_i\}_{i \in Q}$
defined as
\vspace{+2pt}
\begin{equation}\label{orst_weights}
\mu_i =\lambda_i \prod_{j \in Q \setminus \{i\}} c_j
\vspace{5pt}
\end{equation}
where $c_i \equiv H(u_i)$ and
$\{\lambda_i\}_{i \in Q }$ are the Lagrange interpolation
coefficients for $Q$.
Under the same notation,
the \textit{normalizer of} $\{u_i\}_{i \in Q}$ is the scalar
\vspace{5pt}
\begin{equation}\label{orst_normalizer}
\bar{c} = \prod_{i \in Q} c_i
\vspace{5pt}
\end{equation}
\end{defn}
\noindent
That is, the verifier juncts the decoupled
proofs through the weights and the normalizer
of the points $\{u_i\}_{i \in Q}$,
which the individual provers respectively commit to.
We have already made use of
the following relation
(cf. Remark \ref{orst_correctness}).

\begin{rem}\label{orst_core_remark}
(\textit{Relation between weights and the normalizer})
Let $\{\mu_i\}_{i \in Q}$, $\bar{c}$ be the weights
and the normalizer of a collection $\{u_i\}_{i \in Q}$
respectively. Then
\vspace{5pt}
\begin{equation}\label{orst_core}
c_i \mu_i = \lambda_i \bar{c},\ \ \forall i \in Q
\vspace{5pt}
\end{equation}
\end{rem}

\begin{defn}\label{orst_proof_def}
By \textit{proof} is meant a collection
$\sigma = \{(u_i, s_i)\}_{i \in Q}$ of the form
\vspace{5pt}
\begin{equation*}\label{orst_proof_form}
(u_i, s_i) \in \mathbb{G} \times \mathbb{Z}_q,
\vspace{2pt}\forall i \in Q
\hspace{3pt}
\land
\hspace{3pt}
Q \subset \{1, \dots, n\}.
\vspace{5pt}
\end{equation*}
Given $\sigma$ as above, we refer to
$\{u_i\}_{i \in Q}$ as its \textit{commitments} and
say that $\sigma$ is \textit{based on} them.
We also refer to $\{s_i\}_{i \in Q}$ as the
\textit{responses}.
The \textit{weights} and \textit{normalizer of} $\sigma$
are the weights and normalizer of its commitments respectively.
The \textit{proof space}
is the set of proofs and will be denoted by $\Sigma$.
We also denote by
\vspace{5pt}
\begin{equation*}\label{orst_proofs_on_commitments}
\Sigma\big[\{u_i\}_{i \in Q}\big]
\vspace{5pt}
\end{equation*}
%\{
%	\hspace{1pt}
%	\sigma \in \Sigma:
%	\exists \{s_i\}_{i \in Q} \textup{ such that }
%	\sigma = \{(u_i, s_i)\}_{i \in Q}
%	\hspace{1pt}
%\}
the subspace of proofs that are
based on the commitments $\{u_i\}_{i \in Q}$.
Evidently, proofs in this subspace
share the same weights and normalizer.
\end{defn}

\noindent
Note that the above proof notion does not impose
constraints on the relation between
the commitments and the responses;
it does not confine
to properly generated transcripts,
modelling the verifier's view in the wild
and including anything that malicious provers can possibly fabricate.
The proper execution of the protocol
is modelled as follows.

\begin{defn}\label{orst_canonical_def}
The proof $\{(u_i, s_i)\}_{i \in Q} \in \Sigma$ is called
\textit{canonical with respect to} a sharing
$(x_1, \dots, x_n;\hspace{2pt} y) \in D_x$ if
\vspace{5pt}
\begin{equation}\label{orst_canonical}
s_i = r_i + c_i \hspace{1pt} x_i,
\ \ \ c_i \equiv H(u_i),
\ \ r_i \equiv \log u_i,
\ \ \forall i \in Q,
\vspace{5pt}
\end{equation}
i.e., its components are Schnorr proof
for the respective shares.
Evidently, the subspace $\Sigma\big[\{u_i\}_{i \in Q}\big]$
contains a unique canonical representative
with respect to every fixed sharing.
\end{defn}

\begin{defn}\label{orst_verifier}
The \textit{one-round Schnorr $(n, t)$-threshold verifier}
is the deterministic algorithm
$\mathcal{V}: \mathbb{G} \times \Sigma \rightarrow
\{\hspace{0.5pt}\textsf{true}, \textsf{false}\hspace{0.5pt}\}$
invoked as
\vspace{5pt}
\begin{equation*}
\big(y, \{(u_i, s_i)\}_{i \in Q}\big)\
\ \mapsto
\ \hspace{4pt}\exp\Big(\hspace{1pt}g, {\sum_{i \in Q} \mu_i s_i}\Big) =
y ^ {\bar{c}} \prod_{i \in Q} u_i^{\mu_i}
\hspace{1pt},
\vspace{5pt}
\end{equation*}
where $\{\mu_i\}_{i \in Q}$, $\bar{c}$ are
the weights and the normalizer of $\{(u_i, s_i)\}_{i \in Q}$
respectively.
\end{defn}

\begin{defn}\label{orst_validity_definition}
A proof $\sigma \in \Sigma$ is called
\textit{valid against} $y \in \mathbb{G}$ if
$\hspace{1pt}\mathcal{V}\hspace{1pt}(y, \sigma)
= \textsf{true}\hspace{1pt}$.
\end{defn}

\noindent
$\mathsf{ORST}$ correctness
(cf. Remark \ref{orst_correctness})
means that a proof canonical with respect
to $(x_1, \dots, x_n;\hspace{2pt} y)$
is valid against $y$ if and only if $|Q| \ge t$.
The subspace of proofs that are based on
$\{u_i\}_{i \in Q}$ and valid against $y$ is denoted by
\vspace{5pt}
\begin{equation*}\label{orst_valid_proofs_on_commitments_def}
\Sigma_y \big[\{u_i\}_{i \in Q}\big]\hspace{1pt}.
\vspace{5pt}
\end{equation*}
%\{
%	\hspace{1pt}
%	\sigma \in \Sigma\big[\{u_i\}_{i \in Q}\big]:
%	\mathcal{V}\hspace{1pt}(y, \sigma) = \mathsf{true}
%	\hspace{1pt}
%\}\hspace{1pt}.
If $|Q| \ge t$, then this space
contains a unique canonical representative
with respect to every fixed sharing of $x = \log y$.

\begin{rem}
In the non-distributed case $t=1$, the subspace
$\Sigma_y \big[\{u_i\}_{i \in Q}\big]$
is a singleton due to the ``unique responses'' property
of the Schnorr protocol.
That is, for every $u \in \mathbb{G}$
there exists a unique $s$
such that the proof $(u, s)$ is valid against $y=g^x$,
namely $s = r + H(u)\hspace{1pt}x$ with $r \equiv \log u$.
In general, however,
this space inflates dramatically
at a rate dependent on $|Q| \ge t$
(cf. Remark \ref{orst_valid_above_rem}).
This implies an abundance of valid proofs that
are non-canonical, a fact that
every relevant security notion should be able to capture.
\end{rem}

\begin{prop}\label{orst_validity_conditions}
\textup{(\textit{Validity conditions})}
Let $x \in \mathbb{Z}_q$, $y = g ^ x$ and
$\sigma = \{(u_i, s_i)\}_{i \in Q}$.
Then, with overwhelming probability,
$\sigma$ is valid against $y$
if and only if
\vspace{5pt}
\begin{equation}\label{orst_verification_1}
\frac{1}{\ \bar{c}\ }
\hspace{1pt}
\sum_{i \in Q}
	\hspace{0.5pt} \mu_i (s_i - r_i)
=
x,
\ \ r_i \equiv \log u_i\hspace{1pt},
\vspace{5pt}
\end{equation}
where $\{\mu_i\}_{i \in Q}$, $\bar{c}$
are its weights and normalizer respectively
or, equivalently,
\vspace{5pt}
\begin{equation}\label{orst_verification_2}
\hspace{-12pt}x
=
\sum_{i \in Q} \lambda_i\hspace{1pt}\frac{s_i - r_i}{c_i},
\vspace{5pt}
\end{equation}
where $c_i \equiv H(u_i)$
and $\{\lambda_i\}_{i \in Q}$ are the interpolation
coefficients for $Q$.
\end{prop}

\begin{proof}
Since $H$
is a secure hash function,
we have
$\bar{c} \neq 0$ with overwhelming probability
in the bitlength of the group order.
In this case,
the verification condition \eqref{orst_verification_exponents}
becomes \eqref{orst_verification_1}.
This further reformulates to
\eqref{orst_verification_2} by means of \eqref{orst_core}.
\vspace{5pt}
\end{proof}

\noindent
This statement holds true irrespective of size
(including the case $|Q| < t$),
establishing a relation between $x$ and any proof
that happens to be valid against $y$.
Both \eqref{orst_verification_1} and \eqref{orst_verification_2}
generalize the relation of a secret key to a
valid non-distributed proof;
it should be stressed however that
\eqref{orst_verification_2} does not imply
$x_i = (r_i - s_i)/c_i$ and
can hold true without $\sigma$ being canonical.
Indeed (cf. Remark \ref{orst_validity_degrees_of_freedom}),
valid proofs do not confine to those properly
generated in \textsf{ORST} and a relevant security notion
should ensure that such proofs are infeasible to compute
without knowledge of at least $t$ shares
(cf. Section \ref{section_security_notions}).
The exact meaning of \eqref{orst_verification_2}
is clarified in Proposition \ref{orst_uniqueness_sharing}.
Evidently, a proof should not verify against
different public keys.
In fact, this key almost always exists and it is unique.

\begin{prop}\label{orst_uniqueness_public_key}
\textup{(\textit{Almost every proof is valid against
some unique public key})}
Given commitments $\{u_i\}_{i \in Q} \subset \mathbb{G}$,
then, with overwhelming probability,
every $\sigma \in \Sigma$ based on them
is valid against some unique $y \in \mathbb{G}$.
\end{prop}

\begin{proof}
Let $\{\mu_i\}_{i \in Q}$, $\bar{c}$
be the weights and the normalizer of $\{u_i\}_{i \in Q}$,
which are common to all proofs based on them.
Since $H$ is a secure hash function,
$\bar{c} \neq 0$ with overwhelming probability in
the bitlength of the group order.
Consequently, given any proof of the form
$\sigma = \{(u_i, s_i)\}_{i \in Q}$, we can define
\vspace{5pt}
\begin{equation*}
x = \frac{1}{\ \bar{c}\ }
\sum_{i \in Q} \mu_i\hspace{1pt}(s_i - r_i)\hspace{1pt},
\vspace{5pt}
\end{equation*}
where $r_i \equiv \log u_i$.
By Proposition \ref{orst_validity_conditions},
$\sigma$ is valid against $y = g ^ x$ solely.
\vspace{5pt}
\end{proof}

\begin{cor}\label{orst_validity_classes_prop}
Given $\{u_i\}_{i \in Q} \subset \mathbb{G}$,
then, with overwhelming probability,
\vspace{5pt}
\begin{equation}\label{orst_validity_classes_union}
\Sigma\big[\{u_i\}_{i \in Q}\big]
=
\bigcup_{y \in \mathbb{G}} \Sigma_y\big[\{u_i\}_{i \in Q}\big]
\vspace{3pt}
\end{equation}
where the right-hand side is a partition, i.e.,
\vspace{7pt}
\begin{equation*}
\Sigma_y\big[\{u_i\}_{i \in Q}\big]
\cap
\Sigma_{y^*}\big[\{u_i\}_{i \in Q}\big]
= \varnothing
\ \textit{ for }\ y \neq y^*.
\vspace{7pt}
\end{equation*}
\end{cor}

\begin{proof}
Direct consequence of Proposition \ref{orst_uniqueness_public_key}.
\end{proof}

\begin{prop}\label{orst_uniqueness_sharing}
\textup{(\textit{Almost every proof of size $|Q| = t$
is canonical with respect to some unique sharing})}
Given commitments
$\{u_i\}_{i \in Q} \subset \mathbb{G}$ with $|Q| = t$,
then, with overwhelming probability,
every $\sigma \in \Sigma$ based on them
is canonical with respect to some unique sharing
$(x_1, \dots, x_n;\hspace{1pt} y) \in D_x$
of some unique $x \in \mathbb{Z}_q$.
\end{prop}

\begin{proof}
Let $\{\mu_i\}_{i \in Q}$
be the weights of $\{u_i\}_{i \in Q}$
and denote $c_i \equiv H(u_i)$.
Note that these parameters
are common to all proofs based on the
given commitments.
Since $H$ is a secure hash function,
$c_i \neq 0,\hspace{2pt} \forall i \in Q,$
with overwhelming probability in
the bitlength of the group order.
Consequently, given $\sigma = \{(u_i, s_i)\}_{i \in Q}$,
we can define
\vspace{5pt}
\begin{equation*}
x_i = \frac{s_i - r_i}{c_i},
\ \ i \in Q\hspace{1pt},
\vspace{5pt}
\end{equation*}
where $r_i \equiv \log u_i$.
since $|Q| = t$, the scalars $\{x_i\}_{i \in Q}$
uniquely determine a $(n, t)$-sharing
$(x_1, \dots, x_n;\hspace{1pt} y)$
of some $x \in \mathbb{Z}_q$
by virtue of interpolation.
Since $s_i = r_i + c_i\hspace{1pt}x_i,\hspace{2pt}\forall i \in Q$,
the proof is canonical with respect to this sharing
and thus valid against $y = g ^ x$.
The claim follows from Proposition \ref{orst_uniqueness_public_key}.
\end{proof}

\begin{rem}\label{orst_validity_degrees_of_freedom}
(\textit{Validity and degrees of freedom})
Fix commitments $\{u_i\}_{i \in Q} \subset \mathbb{G}$.
Choose $J \subset Q$ with $|J| = |Q| - 1$,
pick arbitrary $\{s_i\}_{i \in J} \subset \mathbb{Z}_q$
and set
\vspace{5pt}
\begin{equation*}\label{orst_validity_degrees_of_freedom_formula}
s_j
	\hspace{1.5pt}
	=
	\hspace{1.5pt}
	r_j + \frac{1}{\mu_j}
	\hspace{1.5pt}
	\Big(
		\hspace{1.0pt}
		\bar{c}\cdot x
		\hspace{1.5pt}
		-
		\hspace{1.5pt}
		\sum_{i \in J}
			\mu_i
			\hspace{1pt}
			(s_i - r_i)
	\Big)
\vspace{5pt}
\end{equation*}
where $\{\hspace{1pt}j\hspace{1pt}\} = Q \setminus J$
and $r_i \equiv \log u_i$.
By Proposition \ref{orst_validity_conditions},
this process exhausts the proofs
that are based on $\{u_i\}_{i \in Q}$ and valid against
$y \equiv g ^ x$
bijectively.
That is, the subspace
$\Sigma_y \big[\{u_i\}_{i \in Q}\big]$
has $|Q| - 1$ degrees of freedom in the sense that
every proof is determined
by the choice of $\{s_i\}_{i \in J}$
and $J \subset Q$ (for $|Q| = 1$
this is the ``unique responses'' property
of the ordinary Schnorr protocol).
Observe that this process has no obvious utility
for an impersonating adversary,
since the latter would still need
to eliminate $x$ in order to compute $s_j$.
\end{rem}

\begin{prop}\label{orst_validity_against_sharing_prop}
\textup{(\textit{Validity against sharing})}
Let $x \in \mathbb{Z}_q$ and
$\sigma = \{(u_i, s_i)\}_{i \in Q}$.
Given $(x_1, \dots, x_n;\hspace{1pt} y) \in D_x$,
the proof $\sigma$ is valid against $y$ if and only if
\vspace{5pt}
\begin{equation}\label{orst_validity_against_sharing}
\sum_{i \in Q} \mu_i\hspace{1pt} (s_i - r_i - c_i\hspace{1pt}x_i)
=
\bar{c} \cdot \Big(x - \sum_{i \in Q} \lambda_i x_i\Big),
\vspace{5pt}
\end{equation}
\end{prop}

\begin{proof}
Follows from the verification condition
\eqref{orst_verification_exponents}
by substracting
\vspace{5pt}
\begin{equation*}
\sum_{i \in Q} \mu_i\hspace{0.5pt}c_i\hspace{0.5pt}x_i
\vspace{5pt}
\end{equation*}
on both sides and applying \eqref{orst_core}
on the right.
\end{proof}

\begin{rem}\label{orst_valid_below_rem}
(\textit{Valid proofs with $|Q| < t$})
We know that if a proof of size $<t$ is valid,
then it cannot be canonical (cf. Remark \ref{orst_correctness}).
Such proofs exist in abundance
(cf. Remark \ref{orst_validity_degrees_of_freedom})
and Prop. \ref{orst_validity_against_sharing_prop}
indicates a way to generate them programmatically.
Fix $\{u_i\}_{i \in Q} \subset \mathbb{G}$
and set $s_i = r_i + c_i\hspace{1pt}x_i$, where
$r_i \equiv \log u_i$, $c_i \equiv H(u_i)$.
Pick $S \subset Q$ with $S \neq \varnothing$
and define
$s_i^* = s_i$ if $i \not \in S$, otherwise
\vspace{5pt}
\begin{equation*}
s_i^* = s_i + \delta_i,
\ \ \ \delta_i
	\hspace{1pt}
	\equiv
	\hspace{1pt}
	\frac{1}{\mu_i}
	\cdot
	\frac{\bar{c}}{|S|}
	\cdot
	\Big(
		x
		-
		\sum_{j \in Q} \lambda_j x_j
	\Big)
	\hspace{1pt}
	,
\vspace{5pt}
\end{equation*}
where $\bar{c}$ is the normalizer of $\{u_i\}_{i \in Q}$.
Consider the proof $\sigma = \{(u_i, s_i)\}_{Q}$.
If $|Q| \ge t$, then $\delta_i = 0,\hspace{2pt} \forall i \in S,$
so that $\sigma$ is canonical and thus automatically valid.
If $|Q| < t$, then $\sigma$ still remains valid because
it satisfies \eqref{orst_validity_against_sharing}
by design.
Note however that this construction has no obvious utility
for a malicious coalition $Q \subset \{1, \dots, n\}$
with $|Q| < t$ since the colluders
(or, equivalently, an impersonating adversary
who knows $\{x_i\}_{i \in Q}$)
would still need to know $x$ in order to adjust
the $\delta_i$'s appropriately.
\end{rem}

\begin{cor}\label{orst_validity_above_prop}
\textup{(\textit{Validity against sharing, $|Q| \ge t$})}
Let $x \in \mathbb{Z}_q,\ \sigma = \{(u_i, s_i)\}_{i \in Q}$
with $|Q| = t$.
Given $(x_1, \dots, x_n;\hspace{1pt} y) \in D_x$,
$\sigma$ is valid against $y$ if and only if
\vspace{5pt}
\begin{equation}\label{orst_validity_above}
\sum_{i \in Q} \mu_i s_i =
\sum_{i \in Q} \mu_i\hspace{1pt}(r_i + c_i x_i),
\vspace{5pt}
\end{equation}
where $r_i \equiv \log u_i$, $c_i \equiv H(u_i)$
and $\{\mu_i\}_{i \in Q}$
are the weights of $\sigma$.
\end{cor}
\begin{proof}
The right-hand side of \eqref{orst_validity_against_sharing}
vanishes exactly if $|Q| \ge t$.
\end{proof}

\begin{rem}\label{orst_t_1_degrees_of_freedom}
(\textit{$t-1$ degrees of freedom})
Fix $\{u_i\}_{i \in Q}$ with $|Q| = t$.
Choose $J \subset Q$ with $|J| = t - 1$,
pick arbitrary $\{\delta_i\}_{i \in J} \subset \mathbb{Z}_q$
and set
\vspace{5pt}
\begin{equation*}
s_j
	\hspace{2pt}
	=
	\hspace{2pt}
	r_j
	\hspace{1pt}
	+
	\hspace{1pt}
	c_j\hspace{1pt}x_j
	\hspace{1pt}
	-
	\hspace{1pt}
	\frac{1}{\mu_j}
	\hspace{1pt}
	\sum_{i \in J}
		\mu_i
		\hspace{1pt}
		(
			s_i - r_i - c_i\hspace{1pt}x_i
		),
\vspace{5pt}
\end{equation*}
where $\{\hspace{0.5pt}j\hspace{0.5pt}\} = Q \setminus J$ and
$r_i \equiv \log u_i$, $c_i \equiv H(u_i)$.
By Corollary \ref{orst_validity_above_prop},
this process exhausts the proofs
that are based on $\{u_i\}_{i \in Q}$
and valid against $y$ bijectively.
This is a special case of Remark
\ref{orst_validity_degrees_of_freedom}
with reference to a fixed sharing.
Observe that it has no obvious utility
for an adversary who knows $\{x_i\}_{i \in J}$
but not $x_j$.
\end{rem}

\begin{rem}\label{orst_valid_above_rem}
(\textit{Valid proofs with $|Q| \ge t$})
This can be seen from a more general perspective.
Consider a canonical proof $\{(u_i, s_i)\}_{i \in Q}$
with $|Q| \ge t$ and let $\{\mu_i\}_{i \in Q}$ be its weights.
Pick $j \in Q$ and arbitrary scalars
$\delta_i,\hspace{2pt} i \in Q \setminus \{j\},$
such that at least one is non-zero.
If we define
\vspace{5pt}
\begin{equation*}
\delta_j = - \frac{1}{\mu_j}
\sum_{i \neq j} \mu_i \delta_i,
\vspace{5pt}
\end{equation*}
then the proof $
	\{
		(
			\hspace{1pt}
			u_i,
			\hspace{1pt}
			s_i
			\hspace{1pt}
			+
			\hspace{1pt}
			\delta_i
		)
	\}_{i \in Q}$
satisfies condition \eqref{orst_validity_above}
by design. Evidently, this process exhausts the valid proofs
that are based on $\{u_i\}_{i \in Q}$ bijectively
(cf. Corollary \ref{orst_validity_above_prop}).
\end{rem}

\subsection{Multi-round executions}\label{section_multi_round}

While $\mathsf{ORST}$ has been designed so that
the shareholders can act independently and asynchronously,
any $|Q| \ge t$ provers have the option to collaboratively
generate a valid non-canonical proof without
revealing their secret shares to each other,
%(as indicated by Remark \ref{orst_valid_above_rem}),
provided that traceable communication channels
exist between them and the network overhead
due to their interaction is not prohibiting.
One possible reason is that the provers
may want to blind their individual identities
for privacy and anonymity.
Multi-round executions are also important from the security viewpoint,
since they cover a wide range of impersonating strategies.
As shown below, every valid proof of size $t^* \ge t$
is essentially the result of a multi-round execution,
implying that the threat model of the $\mathsf{ORST}$
protocol must be actually formulated in the general multi-round setting.

Regarding anonymity, observe  that a man-in-the-middle
who intercepts a canonical proof
$\{(u_i, s_i)\}_{i \in Q}$ can trivially
infer the involved provers' public shares in the form
\vspace{5pt}
\begin{equation}\label{orst_leaked_public}
y_i =
\sqrt[\leftroot{0}\uproot{10}c_i]{\frac{u_i}{g ^ {s_i}}}
\ \ c_i \equiv H(u_i)
\vspace{5pt}
\end{equation}
\noindent
However, instead of sending the packets
$(u_i, s_i),\hspace{2pt} i \in Q,$ to the verifier,
the provers can first engage in the multi-party computation
of scalars $\{\delta_i\}_{i \in Q}$ such that
\vspace{5pt}
\begin{equation}\label{orst_deviations}
\sum_{i \in Q} \mu_i \delta_i = 0
\vspace{5pt}
\end{equation}
and send the respective packets $(u_i, s_i^*),\hspace{2pt} i \in Q,$
where $s_i^* = s_i + \delta_i$.
Indeed, if $|Q| \ge t$
then the proof $\{(u_i, s_i^*)\}_{i \in Q}$ remains valid because
\vspace{5pt}
\begin{equation*}
\sum_{i \in Q} \mu_i s_i^* =
\sum_{i \in Q} \mu_i s_i + \sum_{i \in Q} \mu_i \delta_i = 
\sum_{i \in Q} \mu_i s_i
\vspace{5pt}
\end{equation*}
\noindent
(cf. Corollary \ref{orst_validity_above_prop}).
In this case, if $\delta_i \neq 0$, then
\vspace{5pt}
\begin{equation*}\label{orst_thetas}
y_i \neq \theta_i,
\ \ \theta_i \equiv
\sqrt[\leftroot{0}\uproot{10}c_i]{\frac{u_i}{g ^ {\hspace{1pt}s_i^*}}}
\vspace{5pt}
\end{equation*}
and anonymity follows because $y_i$
cannot be feasibly inferred from $\theta_i$,
provided that the $\delta_i$'s
remain private to the group of involved provers.
We refer to $\{\delta_i\}_{i \in Q}$
as the \textit{blinding factors}.
Note that the provers can follow almost arbitrary
multi-round strategies
in order to compute their blinding factors
(cf. Remark \ref{orst_valid_above_rem}).
If they want to keep them
in private and do not trust each other,
they can operate as follows.
They first execute a DKG protocol
in order to generate a verifiable $(n, t)$-sharing
$(\eta_1, \dots, \eta_n;\hspace{2pt} 1)$
of the zero scalar, so that $\eta_i$
remains known only to the $i$-th shareholder.
By the homomorphic property of Shamir's secret sharing,
$(x_1 + \eta_1, \dots, x_n + \eta_n;\hspace{2pt} y)$
remains a $(n, t)$-sharing of the group secret $x$.
Consequently,
the provers can proceed to the proving phase of $\mathsf{ORST}$
and generate a valid proof that is
canonical with respect to this sharing.
Although not explicitly computed,
the blinding factors are here
$\delta_i = c_i\hspace{0.5pt}\eta_i$.
By Proposition \ref{orst_uniqueness_sharing},
any multi-round execution is essentially equivalent
to an execution of this kind.

\subsection{Security considerations}

Since $\mathsf{ORST}$
decouples into concurrent executions
of the ordinary Schnorr protocol, any security precaution
regarding the latter applies also in the threshold case.
For example, security against side-channel attacks
cannot be attained if the random number generator
leaks linear relations between the discrete logarithms
of distinct commitments.
We here focus on high-level attacks that
arise particularly in the distributed setting.

\subsubsection{Generalized replay attack}\label{section_generalized_replay_attack}

\textsf{ORST}
is as much susceptible to replay attacks
as the ordinary Schnorr protocol.
That is, a man-in-the-middle
can passively capture and replay
the packets sent by a coalition
of shareholders in order to impersonate them anytime.
Things seem worse
because the attacker can transform the
intercepted proof
almost arbitrarily,
provided that its commitments are kept fixed.
Let
$\{(u_i, s_i)\}_{i \in Q}$ be a
valid proof with $|Q| \ge t$ and weights $\{\mu_i\}_{i \in Q}$.
For fixed $j \in Q$,
pick $\{\delta_i\}_{i \in J} \subset \mathbb{Z}_q$
for $J = Q \setminus \{j\}$ and define
\vspace{5pt}
\begin{equation*}
\delta_j = -\hspace{1pt} \frac{1}{\mu_j}\sum_{i \in J} \mu_i \delta_i\hspace{1pt}.
\vspace{5pt}
\end{equation*}
Then $\{(u_i, s_i^*)\}_{i \in Q}$ with
$s_i^* = s_i + \delta_i$ remains valid bacause
\vspace{5pt}
\begin{equation*}
\sum_{i \in Q} \mu_i s_i^* =
\sum_{i \in Q} \mu_i s_i + \Big(\mu_j \delta_j + \sum_{i \in J} \mu_i \delta_i\Big) = 
\sum_{i \in Q} \mu_i s_i
\vspace{5pt}
\end{equation*}
\noindent
(cf. Corollary \ref{orst_validity_above_prop}).
This essentially exploits the structure described in
Remark \ref{orst_valid_above_rem}.
That is, in case of interception,
the attacker has $t-1$ degrees of freedom
in fabricating a valid proof based on the same commitments.
This generalizes the replay attack of the non-distributed
case $t=1$, where the intercepted proof can only be replayed as is.
It should be clear that
generalized replay attacks are
mitigated by the same method as in the non-distributed case,
i.e., by baking a nonce into the hash function,
capable of maintaining state between
the verifier and the involved provers.

\subsubsection{Non-accountability}\label{section_non_accountability}
Since the verifier does not generally
maintain any trusted shares,
$\mathsf{ORST}$ is inherently non-accountable.
In particular, if an acclaimed shareholder sends
a maliciously fabricated packet $(u_j, s_j)$
such that \eqref{orst_verification_0}
resolves to $\mathsf{false}$, the index $j$
is generally untraceable
for, say, security investigation purposes.
If a use case presupposes that the
public shares $y_i=g^{x_i},\hspace{2pt} 1 \le i \le n,$
are trustedly advertised along with $y$ during the setup phase
and registered on the verifier's side,
the latter can accurately blame cheating $j$'s by
checking which of the conditions
$
y_i \hspace{0.5pt}
=
\hspace{0.5pt}
g^{\hspace{0.5pt}s_i}\hspace{0.5pt} u_i\hspace{0.5pt},
\hspace{2pt} i \in Q,
$
are not satisfied.

Accurate blaming is sometimes possible in the general case.
Suppose that the verifier has already
identified a coalition of parties
$Q \subset \{1, \dots, n\}$
and an acclaimed shareholder sends a delayed packet
$(u_j, s_j),\hspace{2pt} j \not \in Q,$ such that
\eqref{orst_verification_0}
resolves to $\mathsf{false}$
for $Q \leftarrow Q \cup \{\hspace{0.5pt}j\hspace{0.5pt}\}$;
the verifier can then deny access to $j$ separately
without this affecting the session for the rest shareholders.
More generally, suppose that the verifier has aggregated
the proof packets for an index set $Q^* \subset \{1, \dots, n\}$
and follows an incremental verification strategy.
That is, instead of verifying all of them at once,
the verifier tries combinations of increasing size until
it hits a verifying collection of size $t$.
If feasible, the verifier can then exhaust all combinations
$Q \subset Q^*$ of size $|Q| = t$ in order
to possibly detect cheating indexes, while maintaining a list
with the honest ones.

\subsubsection{Key-recovery attack -- interactive aspect}\label{section_key_recovery_attack}
This affects only
the interactive version of the protocol
(cf. Remark \ref{orst_interactive})
under rather special circumstances,
but sheds light on its inherent security structure.
Similar to the non-distributed case,
we will employ this attack in order to derive
a formal security proof by means of fork and extraction
(cf. Section \ref{section_extractability}).
Evidently, if a shareholder uses the same commitment
in two canonical executions of the interactive $\mathsf{ORST}$ protocol
(due to, say, broken random  number generator),
then its secret share leaks trivially
like in the non-distributed case.
This is ordinary key-recovery
embedded into the canonical threshold setting.
We will show that key-recovery
is possible even for non-canonical (i.e., multi-round) executions
(cf. Section \ref{section_multi_round})
in the presence of a malicious verifier who controls $t-1$ shareholders.

Let $Q = J \cup \{j\}$ be a coalition of shareholders
such that $|J| = t-1$ with $j \not \in J$
and the cluster $J$ is controlled by an adversary $\mathcal{A}^*$.
We further assume that $\mathcal{A}^*$
controls the identifying server.
The shareholders engage in a multi-round
session and generate a transcript $\{(u_i, c_i, s_i)\}_{i \in Q}$
that verifies, so that
\vspace{5pt}
\begin{equation*}
\sum_{i \in Q}
\mu_i\hspace{0.5pt} (s_i - r_i - c_i\hspace{1pt}x_i)
=
0
\vspace{5pt}
\end{equation*}
holds true,
where $r_i \equiv \log u_i$
and $\{\mu_i\}_{i \in Q}$ are the weights
induced by the challenges $\{c_i\}_{i \in Q}$.
(cf. Corollary \ref{orst_validity_above}).
They next engage in a second session,
where the $j$-th shareholder reuses $u_j$.
After receiving $u_j$ on the server's side,
$\mathcal{A}^*$ responds with a challenge $c_j^* \neq c_j$
and tunes the rest shareholders to
reuse the commitments $u_i,\hspace{2pt} i \in J,$
from the previous session. To each of them,
the server responds with the same challenge
$c_i^* = c_i$
from the previous session.
Subsequently, the provers compute honestly their respective
responses $s_i,\hspace{2pt} i \in Q,$
and send them to the server;
since the transcript $\{(u_i, c_i^*, s_i^*)\}_{i \in Q}$
verifies, we again have
\vspace{5pt}
\begin{equation*}
\sum_{i \in Q}
\mu_i^*\hspace{0.5pt} (s_i - r_i - c_i^*\hspace{1pt}x_i)
=
0\hspace{1pt},
\vspace{5pt}
\end{equation*}
where $\{\mu_i^*\}_{i \in Q}$ are the weights induced
by the challenges $\{c_i^*\}_{i \in Q}$.
Note that,
since $c_i = c_i^*$ for all $i \neq j$,
by definition of weights
(cf. Definition \ref{orst_weights_definition})
we get $\mu_j = \mu_j^*$.
Substracting terms in the above relations and applying this remark,
we get
\vspace{5pt}
\begin{equation*}
\mu_j (s_j - s_j^* - (c_j - c_j^*)\hspace{1pt} x_j)
\hspace{2pt}
+
\hspace{1pt}
\sum_{i \in J}\hspace{1pt}
(
\hspace{1pt}
\mu_i (s_i - r_i - c_i x_i)
-
\mu_i^* (s_i^* - r_i - c_i x_i)
\hspace{1pt}
)
=
0\hspace{1pt}
\vspace{5pt}
\end{equation*}
This eliminates $r_j$,
which is the only unknown to the adversary.
Since $c_j - c_j^* \neq 0$, the adversary
$\mathcal{A}^*$ can use this relation to retrieve
$x_j$ in the form
\vspace{5pt}
\begin{equation}\label{orst_key_recovery}
x_j
\hspace{2pt}
=
\hspace{2pt}
\frac{s_j - s_j^*}{c_j - c_j^*}
\hspace{2pt}
+
\hspace{2pt}
\frac{1}{\mu_j} \sum_{i \in J}
\hspace{0pt}
\Big(
	\mu_i (s_i - r_i - c_i x_i) -
	\mu_i^* (s_i^* - r_i - c_i x_i)
\Big)\hspace{1pt}
\vspace{5pt}
\end{equation}
\noindent
Note that since $|Q| = t$, the adversary can use
the shares $\{x_i\}_{i \in Q}$
to also recover the combined secret key
by means of Shamir's reconstruction formula.

\section{Security notions}\label{section_security_notions}

\noindent
We specify the threat model for the
$\mathsf{ORST}$ protocol.
Formulations are given in terms of attack games within the
asymptotic paradigm and negligibility
is meant with respect to the bitlength
of the group order.
In Section \ref{section_general_threat_model}, we outline
security against impersonation attacks
and correlate it with a pragmatic security requirement,
namely a distributed knowledge property.
In Section \ref{section_extractability_and_omdl},
we argue that this property cannot be derived
under discrete-logarithm ($\mathsf{DL}$) hardness
without further assumptions,
implying that security against impersontation
attacks is most probably irreducible
to the latter; however, we observe that the stronger
one-more discrete-logarithm ($\mathsf{OMDL}$) herdness assumption
is sufficient for deriving the knowledge property or,
equivalently, yields the missing premises
for a formal security proof based on fork and extraction.
In Section \ref{section_omdl_implications}
we examine some direct consequences of $\mathsf{OMDL}$ hardness
and narrow our attack model
so that the sufficient conditions of extractability are satisfied.
The working model for black-box impersonation attacks is presented
in Section \ref{section_security_imp}
and the $\mathsf{OMDL}$ hardness assumption
(cf. \cite{paper_bellare_palacio}, \cite{paper_bellare_omdl})
is summarized in Section
\ref{section_omdl_hardness}.


\subsection{Threat model}\label{section_threat_model}

The current standard for identification protocols is
security against active impersonation attacks. This refers to
adversaries who not only passively intercept identification
sessions before mounting their actual attack,
but also engage in them actively by impersonating
a legitimate verifier (e.g., by cloning a website in order
to collect information about the user's credentials);
after several such interactions, the adversary switches roles
and attempts to identify itself against some verifier as a
legitimate user.
We will not pursue this path, focusing
on adversaries who only intercept
identification sessions and potentially exert
some control over the network.
Once the relation between threshold and ordinary
Schnorr indentification has been clarified
from the provability viewpoint,
security against active adversaries should be straightforward
to establish using techniques similar to those
of \cite{paper_bellare_palacio}
due to the decoupled structure of the threshold protocol.

\subsubsection{General threat model}\label{section_general_threat_model}

In most general terms, the $\textsf{ORST}$ threat model
consists of an
adversary $\mathcal{A}$ who compromises the keys
of up to $t-1$ shareholders
and attempts to impersonate some coalition
$Q \subset \{1, \dots, n\}$,
i.e., fabricate a proof
$\{(u_i, s_i)\}_{i \in Q}$ that verifies.
It does not make sense to consider adaptive adversaries
because the proving phase consists of decoupled
packets sent to the verifier;
since no ephemeral quantities are exchanged between the shareholders,
$\mathcal{A}$ has no chance to collect potentially
useful information and decide which of them
to corrupt adaptively.
We can thus confine ourselves to the static model,
assuming that the attacker decides from the outset the
set of corrupted parties.
Adaptive corruption during the execution
of an equivalent DKG protocol in place of Shamir's sharing
belongs to the threat model
of the specific use case.

One could further
assume that $\mathcal{A}$ knows
the public keys of the individual shareholders;
however, these are not used anyhow,
although trivially inferred from protocol transcripts
(cf. \eqref{orst_leaked_public}).
Letting $\mathcal{A}$ know them from the outset
corresponds to a scenario where the public shares
become advertised within the group
for at least some initial timespan
(e.g., for mutual recognition and verification purposes)
and $\mathcal{A}$ compromises the device
of a shareholder who has not yet erased them.
Still, the security proof of
Section \ref{section_main_theorem}
remains intact under this stronger assumption
(cf. Remark \ref{rem_leaked_public_shares}), indicating that
an adversary who controls devices
in the erasure-free model has no greater advantage than an
adversary who only steals keys.

Let $(x_1, \dots, x_n;\hspace{2pt} y)$
be the given $(n, t)$-sharing of some secret $x$
and $\mathcal{A}$ be an adversary who knows
the secret shares
$\{x_i\}_{i \in J}$ with $|J| = t-1$.
Let $Q \subset \{1, \dots, n\}$ be the
sharholders that fall victim to impersonation
under a purportedly valid proof $\{(u_i, s_i)\}_{i \in Q}$
fabricated by $\mathcal{A}$.
Without loss of generality,
$Q \subset J$ or $J \subset Q$.
% Without loss of generality, $Q \subset J$ or $J \subset Q$.
Indeed, since the black-box adversary knows nothing
special about the uncorrupted shareholders,
the choice of $Q$ is irrelevant
(except for its size) in the extent to which
$Q$ intersects with $\{1, \dots, n\} \setminus J$;
the adversary can change $Q$
without this affecting its strategy,
provided that its size $|Q|$ is preserved and
the original intersection with $J$ remains included.
We conclude with the following general attack model.
\begin{itemize}[label=$\bullet$,leftmargin=20pt,rightmargin=0pt]
	\vspace{4pt}
	\item
		\textit{Attack statement and corruption}:
			\begin{itemize}[
				label=$\circ$,leftmargin=17pt,rightmargin=21pt
			]
			\vspace{3pt}
			\item $\mathcal{A}$ chooses $J \subset \{1, \dots, n\}$
				with $|J| = t-1$.
				\vspace{3pt}
			\item $\mathcal{A}$ chooses $Q \subset \{1, \dots, n\}$
				with $Q \subset J$  or $J \subset Q$ and
				sends it along with $J$ to its challenger
				$\mathcal{C}$.
				\vspace{3pt}
			\item $\mathcal{C}$ runs
				$(\hspace{1pt}x_1, \dots, x_n;\hspace{1pt} y\hspace{1pt})
				\leftarrow D(x),\hspace{2pt} x \leftarrow_\$ \mathbb{Z}_q$
				and sends $y, \{x_i\}_{i \in J}$
				to $\mathcal{A}$.
			\vspace{3pt}
			\end{itemize}
	\item \textit{Impersonation}:
		$\mathcal{A}$ outputs a proof of the form
		$\sigma = \{(u_i, s_i)\}_{i \in Q}$.
\vspace{5pt}
\end{itemize}
\hspace*{5pt}%
\begin{minipage}{\dimexpr\textwidth-\parindent\relax}%
\hspace{0pt}
$\mathcal{A}$ wins if $\sigma$ is valid against $y$.
\vspace{5pt}
\end{minipage}%

\noindent
Note that successful impersonation is equivalent
to condition \eqref{orst_verification_1} for $\sigma$.
Security against impersonation attacks should mean
that every polynomial-time adversary wins the above game
with negligible advantage.
The pragmatic requirement behind is that,
if $\mathcal{A}$ outputs a proof
$\{(u_i, s_i)\}_{i \in Q}$ that verifies,
then it should necessarily know $x_j$ for some $j \not \in J$;
or, in other words,
impersonation should be infeasible
without knowledge of at least $t$ secret shares.
We will refer to this design requirement
as the \textit{knowledge property}.

This is instance of a more general pattern.
Security notions for Schnorr-based protocols
are naturally intermediated by some
contextual knowledge property like above,
which is the pragmatic security requirement behind.
Consequently,
a security reduction argument should (most probably)
proceed by forking a successful attack and recovering
the relevant secret key;
by knowing this key, the adversary solves
the $\mathsf{DL}$ or related hard problem,
implying that its attack cannot have succeded
with non-negligible chances.
In particular, by rewinding the winning adversary
at some special point and letting it repeat its attempt,
the rewinder \textit{extracts} the key
from the partially differing transcripts
of the two successful attacks.
Security reduces to the hardness assumption only because
extraction yields the solution to the underlying hard problem
under any circumstances that allow rewinding;
if extraction is not possible under certain circumstances,
security is (most probably)
unprovable without further assumptions.
%It should be stressed that extraction
%is only the way to capture
%the knowledge property in a formal reduction argument;
%this property can hold true and pragmatically
%guaruantee security without being per se provable
%under a given hardness assumption.
Regarding $\mathsf{ORST}$,
the relevant extraction formula for $x_j$
is evidently equation \eqref{orst_key_recovery}
from the key-recovery attack
of Section \ref{section_key_recovery_attack}.
We will see
(cf. Section \ref{section_extractability_and_omdl})
that this formula is insufficient for retrieving $x_j$
under certain circumstances,
indicating that $\mathsf{ORST}$ security
is (most probably) irreducible
to $\mathsf{DL}$ hardness alone.
We need extra assumptions in order
for security to become provable
or, what is equivalent,
reduce it to an easier problem than $\mathsf{DL}$.


\subsubsection{Extractability and $(t-1)$-$\mathsf{OMDL}$ hardness}\label{section_extractability_and_omdl}
Consider the following situation with
$Q = J \cup \{\hspace{0.5pt}j\hspace{0.5pt}\}$ and
$|J| = t-1$.
The shareholders $i \in Q$ engage
in a multi-round session
(cf. Section \ref{section_multi_round})
with an interactive verifier
(cf. Remark \ref{orst_interactive}),
where an adversary $\mathcal{A}$
acts as the acclaimed $j$-th shareholder.
We further assume that $\mathcal{A}$
knows the shares $\{x_i\}_{i \in J}$
and can intercept the communication
of the other shareholders.
In particular, $\mathcal{A}$ captures
$u_i, c_i,\hspace{2pt} i \in J$.
Next, $\mathcal{A}$ fabricates a commitment $u_j$
according to some-black-box strategy and sends it to the
verifier, who responds with $c_j$.
Subsequently, the shareholders
perform some multi-party computation
to generate responses $s_i,\hspace{2pt}i\in Q$.
Specifically, $\mathcal{A}$ fabricates a response $s_j$
according to some black-box strategy and sends it to the verifier.
If the protocol is secure, then the transcript
$u_i, c_i, s_i,\hspace{2pt} i \in Q,$
should verify with at most negligible chances
even though $\mathcal{A}$ knows
$x_i, u_i, c_i,\hspace{2pt} i \in J,$
while fabricating $u_j$ and $s_j$.
Pragmatically, if the transcript verifies,
then $\mathcal{A}$ should necessarily know $x_j$.

Extraction proceeds as follows.
Let $\mathcal{A}^*$ be an algorithm with rewindable
black-box access to $\mathcal{A}$.
If $\mathcal{A}$ fabricates
$u_j,\hspace{2pt} s_j$ such that
the transcript $u_i, c_i, s_i,\hspace{2pt} i \in Q,$
verifies with probability $\varepsilon$,
then $\mathcal{A}^*$ rewinds $\mathcal{A}$
exactly before sending $u_j$ and
lets it repeat its impersonation attempt.
By the forking lemma
(cf. \cite{paper_bellare_musig},
or the reset lemma \cite{paper_bellare_palacio}),
$\mathcal{A}$ succeeds again with probability
$\varepsilon^* \approx \varepsilon ^ 2$.
Let $u_i^*, c_i^*, s_i^*,\hspace{2pt}i \in Q,$ be the
trancript of the second impesonation attack;
since rewinding occurs at the last commitment, we have
\vspace{3pt}
\begin{equation}\label{rewinding_condition}
(
	\hspace{0.5pt}
	u_i^* = u_i
	\hspace{2pt}
	\land
	\hspace{2pt}
	c_i^* = c_i
	\hspace{2pt}
)\hspace{2pt}\forall i \in J
\hspace{2pt}
\land
\hspace{2pt}
u_j^* = u_j
\hspace{2pt}
\land
\hspace{2pt}
c_j^* \neq c_j\hspace{1pt},
\vspace{3pt}
\end{equation}
where the last inequality holds with overwhelming probability true.
Extractability means that
$\mathcal{A}^*$ should be able to recover $x_j$
from the transcripts of the two
impersonation attacks and the known shares.
We now contend that this is (most probably) impossible
without further assumptions.
Condition \eqref{rewinding_condition} implies that the
computations of Section \ref{section_key_recovery_attack}
apply in the present context,
meaning that the relevant extraction
formula is the same as \eqref{orst_key_recovery}.
However, $\mathcal{A}^*$
cannot know the logarithms $r_i,\hspace{2pt} i \in J,$
of the intercepted commitments
and consequently cannot use
this formula to recover $x_j$.
Extraction is not possible in the present context.

Since there exist circumstances where
extraction cannot complete without further assumptions,
security is (most probably)
not punrovable without further assumptions as well.
In particular,
$\mathsf{ORST}$ security
against impersonation attacks is (most probably)
not reducible to $\mathsf{DL}$ hardness alone,
at least not until a different extraction formula is discovered.
Nevertheless, $\mathcal{A}^*$ would be able to extract $x_j$
if it could somehow see the logarithms
of the intercepted commitments, e.g.,
if it controlled the respective shareholders' devices
or could at least subvert their random number generator
or other security sensitive module.
We can codify such scenarios under the assumption
that $\mathcal{A}^*$ is allowed to issue at most
$t-1$ queries to a hypothetical $\mathsf{DL}$ oracle;
extraction of $x_j$
would then become possible,
suggesting that security against impersonation attacks
might as well be reducible to
$(t-1)$-$\mathsf{OMDL}$ hardness
(cf. Section \ref{section_omdl_hardness}).
Note that $(t-1)$-$\mathsf{OMDL}$ is indeed
an easier problem than $\mathsf{DL}$,
plausibly yielding the missing premises needed
for security provability.


\subsubsection{Implications of $(t-1)$-$\mathsf{OMDL}$ hardness}\label{section_omdl_implications}

The black-box pattern of the previous section
is rather restricted as compared to
the general attack model of
Section \ref{section_general_threat_model}.
This is because $\mathcal{A}$ does
not influence the compromised shareholders,
mounting its actual attack only after collecting their
transcripts; in particular,
the fabrication of $u_j$ and $s_j$
is deferred until after $u_i, c_i,\hspace{2pt} i \in J,$
have resolved,
in order for extractability failure
to be demonstrated in the simplest possible way
(i.e., by rewinding instead of some more complicated forking argument).
The same argument
indicates in which way security becomes provable under
the stronger $(t-1)$-$\mathsf{OMDL}$ hardness assumption.
Specifically, in order to be able to apply extraction,
$\mathcal{A}^*$ should at least reproduce
the conditions of Remark \ref{section_key_recovery_attack}
and let $\mathcal{A}$ operate in that context.
While this still remains more restricted than the general attack model,
it generalizes by far the restricted attack pattern of
the previous section, allowing
$\mathcal{A}$ to, say, fabricate $u_j$ before the rest shareholders
send their commitments or mount its own responses
by obstructing their communication.
We propose the following preliminary attack model for $\mathcal{A}$,
representing a tradeoff between
the general attack model of Section \ref{section_general_threat_model}
and security provability
under the $(t-1)$-$\mathsf{OMDL}$ hardness assumption.
\begin{itemize}[label=$\bullet$,leftmargin=20pt,rightmargin=0pt]
	\vspace{4pt}
	\item
		\textit{Attack statement and corruption}:
			\begin{itemize}[
				label=$\circ$,leftmargin=17pt,rightmargin=21pt
			]
			\vspace{3pt}
			\item $\mathcal{A}$ chooses $J \subset \{1, \dots, n\}$
				with $|J| = t-1$ and sends it along with some
				$Q \subset \{1, \dots, n\}$
				to its challenger $\mathcal{C}$.
				\vspace{3pt}
			\item $\mathcal{A}$ chooses $Q \subset \{1, \dots, n\}$
				with $Q \subset J$  or $J \subset Q$ and
				sends it along with $J$ to its challenger
				$\mathcal{C}$.
				\vspace{3pt}
			\item $\mathcal{C}$ runs
				$(\hspace{1pt}x_1, \dots, x_n;\hspace{1pt} y\hspace{1pt})
				\leftarrow D(x),\hspace{2pt} x \leftarrow_\$ \mathbb{Z}_q$
				and sends $y, \{x_i\}_{i \in J}$
				to $\mathcal{A}$.
			\vspace{3pt}
			\end{itemize}
	\item
		\textit{Interception}:
		$\mathcal{C}$ samples
		$u_i \leftarrow_\$ \mathbb{G},\hspace{2pt} i \in J$
		and sends $\{u_i\}_{i \in J}$
		to $\mathcal{A}$.\vspace{3pt}
	\item \textit{Impersonation}:
		$\mathcal{A}$ outputs a proof of the form
		$\{(u_i, s_i)\}_{i \in Q}$.
\vspace{4pt}
\end{itemize}
\hspace*{5pt}%
\begin{minipage}{\dimexpr\textwidth-\parindent\relax}%
\hspace{3pt}
$\mathcal{A}$ wins if
$\{(u_i, s_i)\}_{i \in Q}$ verifies against $y$.
\vspace{5pt}
\end{minipage}%

\noindent
$\mathsf{ORST}$ security against impersonation attacks
should mean that every polynomial-time adversary wins this game
with negligible advantage.
Observe that no restrictions are yet imposed on $|Q|$,
allowing the adversary to fabricate
a valid proof with less than $t$ components.
This is plausible because proofs of this kind
are known to exist in abundance
(cf. Remarks \ref{orst_validity_degrees_of_freedom}
and \ref{orst_valid_below_rem}).
However, under the $(t-1)$-$\mathsf{OMDL}$ hardness assumption,
fabricating such proofs can be ruled out as infeasible.
Let $\mathcal{A}$ be a polynomial-time adversary
that wins with $Q \subset J$ (i.e., $|Q| < t$).
Write $J = \{\hspace{0.5pt}i_1, \dots i_{t-1}\hspace{0.5pt}\}$
with $i_1 < \dots < i_{t-1}$, so that
$Q = \{\hspace{0.5pt}i_1, \dots, i_m\}$
for some $m \in \{1, \dots, t-1\}$.
We construct a $(t-1)$-$\mathsf{OMDL}$ adversary
$\mathcal{A}^*$ as a wrapper of $\mathcal{A}$
with equal time complexity and advantage.
When given $w_0, \dots, w_{t-1}$ by its challenger
(cf. Game \ref{omdl_attack}),
$\mathcal{A}^*$ sets $y \leftarrow w_0$ and
$u_{i_k} \leftarrow w_k$ for $1 \le k \le t-1$.
Next, $\mathcal{A}^*$ samples
$x_i \leftarrow_\$ \mathbb{Z}_q$ for $i \in J$
and forwards $y, \{x_i\}_{i \in J}$ to $\mathcal{A}$.
By the security property of Shamir's secret sharing
(cf. Remark \ref{shamir_security}),
$y$ and $\{x_i\}_{i \in J}$
determine a $(n, t)$-sharing $x_1, \dots, x_n$
of some $x \equiv \log y$
indistinguishably, meaning that $\mathcal{A}^*$
simulates perfectly the corruption phase of the attack game.
Subsequently, $\mathcal{A}^*$ sends $\{u_i\}_{i \in J}$ to $\mathcal{A}$
and lets it proceed to impersonation;
since its challenger has been perfectly simulated,
$\mathcal{A}$ outputs a valid proof $\{(u_i, s_i)\}_{i \in Q}$
with probability equal to its advantage.
Condition \eqref{orst_verification_1}
is then satisfied and $\mathcal{A}^*$ can recover $x$ by issuing
at most $t-1$ discrete-logarithm queries.
More accurately, $\mathcal{A}^*$ queries
\vspace{5pt}
\begin{equation*}
r_{i_k} \leftarrow \mathcal{O}
	_{\hspace{1pt}\mathbb{G}}
	^{\hspace{1pt}\mathsf{dlog}}(u_{i_k}),
\ \ 1 \le k \le t-1
\hspace{1pt},
\vspace{5pt}
\end{equation*}
and uses $r_{i_k},\hspace{2pt} 1 \le k \le m,$ to compute $x$.
Next,
$\mathcal{A}^*$ sets $z_0 \leftarrow x$
and $z_k \leftarrow r_{i_k},\hspace{2pt} 1\le k \le t-1,$
and wins by forwarding
$z_0, \dots, z_{t-1}$ to its challenger.
In short, if $\mathcal{A}$ succeeds
with non-negligible probability, then $\mathcal{A}^*$
solves $(t-1)$-$\mathsf{OMDL}$ with equal advantage,
which contradicts the hardness assumption.
This straight-line reduction allows us to restrict attention
to the case $J \subsetneq Q$ (i.e. $|Q| \ge t$),
excluding the possibility of impersonating less than $t$
shareholders without knowing $x$.
This is evidently a security requirement for the $\mathsf{ORST}$
protocol, captured by the $(t-1)$-$\mathsf{OMDL}$
hardness assumption; see also Remarks
\ref{orst_validity_degrees_of_freedom} and
\ref{orst_valid_below_rem}.

\subsection{Security against impersonation attacks}\label{section_security_imp}

\noindent
We conclude with the following model
for impersonation attacks against
$\mathsf{ORST}$.
%$
%\mathsf{ORST}
%	_{\hspace{1pt}\mathbb{G},\hspace{0.5pt} n,\hspace{0.5pt} t},
%\hspace{2pt} 1 \le t \le n < q
%$.

\begin{attack_game}\label{orst_attack_impersonation}
\vspace{3pt}
($
	\mathsf{ORST}
		_{\hspace{1pt}\mathbb{G},\hspace{0.5pt} n,\hspace{0.5pt} t}
		^{\hspace{1pt}\mathbf{imp}}
$
-- \textit{Impersonation})
Given adversary $\mathcal{A}$ and challenger $\mathcal{C}$,
\begin{itemize}[label=$\bullet$,leftmargin=20pt,rightmargin=0pt]
	\vspace{3pt}
	\item
		\textit{Attack statement and corruption}:
			\begin{itemize}[
				label=$\circ$,leftmargin=17pt,rightmargin=21pt
			]
			\vspace{3pt}
			\item $\mathcal{A}$ chooses $J \subset \{1, \dots, n\}$
				with $|J\hspace{1pt}| = t - 1$
				and sends it along with some
				$j \in \{1, \dots, n\} \setminus J$
				to the challenger.
				Denote $Q = J \cup \{\hspace{1pt}j\hspace{1pt}\}$.
				\vspace{3pt}
			\item $\mathcal{C}$ runs
				$(\hspace{1pt}x_1, \dots, x_n;\hspace{1pt} y\hspace{1pt})
				\leftarrow D(x), \ x \leftarrow_\$ \mathbb{Z}_q$
				and sends $y, \{x_i\}_{i \in J}$
				to $\mathcal{A}$.
			\vspace{5pt}
			\end{itemize}
	\item
		\textit{Interception}:
		$\mathcal{C}$ samples
		$u_i \leftarrow_\$ \mathbb{G},\hspace{2pt} i \in J$
		and sends $\{u_i\}_{i \in J}$
		to $\mathcal{A}$.\vspace{3pt}
	\item \textit{Impersonation}:
		$\mathcal{A}$ outputs a proof of the form
		$\sigma = \{(u_i, s_i)\}_{i \in Q}$.
\end{itemize}
\hspace*{5pt}%
\begin{minipage}{\dimexpr\textwidth-\parindent\relax}%
\vspace{5pt}
\hspace{3pt}
$\mathcal{A}$ wins if
$\mathcal{V}\hspace{1pt}(y, \sigma) = \textsf{true}$.
\end{minipage}%
\vspace{3pt}
\end{attack_game}

\noindent
The probability that  $\mathcal{A}$ wins
Game \ref{orst_attack_impersonation}
is denoted by
\vspace{5pt}
\begin{equation}\label{orst_advantage_def}
\mathsf{Adv}
	_{\hspace{1pt}\mathbb{G},\hspace{0.5pt} n,\hspace{0.5pt} t}
	^{\hspace{1pt}\mathsf{ORST}}
	\hspace{1pt}
		[\hspace{1pt}
			\mathcal{A}
		\hspace{1pt}]\hspace{1pt}.
\vspace{5pt}
\end{equation}

\noindent
$\mathsf{ORST}$ \textit{security against impersonation attacks
\textup{(\textit{in} $\mathbb{G}$)}}
should mean that \eqref{orst_advantage_def}
is negligible for every choice of $n,\hspace{1pt} t$
and every polynomial-time adversary $\mathcal{A}$.

\begin{rem}\label{rem_adversarial_components}
(\textit{Adversarial components})
By the security property of
Shamir's secret sharing (cf. Remark \ref{shamir_security}),
the parameters $j$ and $J$ (and consequently $Q$)
may be regarded as fixed for $\mathcal{A}$.
In particular, $\mathcal{A}$ is
a pair of non-interactive algorithms
$(\mathcal{A}_0, \mathcal{\bar{A}})$
of the form
\vspace{5pt}
\begin{equation*}\label{adversary_internal}
(\hspace{1pt}j, J\hspace{1pt})
\leftarrow
\mathcal{A}_0(\hspace{1pt}\cdot\hspace{1pt}),\ \ \{(u_i, s_i)\}_{i \in Q} \leftarrow
\mathcal{\bar{A}}\hspace{0.5pt}
	(
		\hspace{0.5pt}
		y,
		\{x_i\}_{i \in J},
		\{u_i\}_{i \in J}
	)
\hspace{0.5pt},
\vspace{5pt}
\end{equation*}
where $\mathcal{\bar{A}}$ consumes $\mathcal{A}$'s view
during the impersonation phase
in order to fabricate $u_j$ and
$\{s_i\}_{i \in Q}$ such that
$\{(u_i, s_i)\}_{i \in Q}$ verifies.
Note that, when using $\mathcal{A}$
in a black-box reduction,
the logarithm of the fabricated commitment $u_j$
cannot be assumed to be known
and we will normally have to
eliminate it from our computations.
\end{rem}

\begin{rem}\label{rem_deterministic_adversaries}
(\textit{Deterministic adversaries})
\noindent
For every adversary $\mathcal{A}$
attacking Game \ref{orst_attack_impersonation},
there exists a deterministic advesary $\mathcal{A}'$
of equal time complexity such that
\vspace{5pt}
\begin{equation*}\label{deterministic_bound}
\mathsf{Adv}
	_{\hspace{1pt}\mathbb{G},\hspace{0.5pt} n,\hspace{0.5pt} t}
	^{\hspace{1pt}\mathsf{ORST}}
	\hspace{1pt}
		[\hspace{1pt}
			\mathcal{A}'
		\hspace{1pt}]
	\hspace{2pt}
	\ge
	\hspace{2pt}
	\mathsf{Adv}
	_{\hspace{1pt}\mathbb{G},\hspace{0.5pt} n,\hspace{0.5pt} t}
	^{\hspace{1pt}\mathsf{ORST}}
	\hspace{1pt}
		[\hspace{1pt}
			\mathcal{A}
		\hspace{1pt}]\hspace{1pt}.
\vspace{5pt}
\end{equation*}

\noindent
This follows from a generic argument
regarding any adversary $\mathcal{A}$
attacking a sufficiently simple game $\mathsf{G}$.
Consider the residual determinisic strategies
$\mathcal{A}_1, \dots, \mathcal{A}_m$ obtained
by fixing the possible values of $\mathcal{A}$'s
random coins and let $p_i$ denote the probability that
$\mathcal{A}$ runs $\mathcal{A}_i$
(which is itself an adversary for $\mathsf{G}$);
we then have
\vspace{0pt}
\begin{equation*}
	\mathsf{Adv}
		^{\mathsf{G}}
		\hspace{1pt}
		[
			\hspace{1pt}
			\mathcal{A}
			\hspace{1pt}
		]
	\hspace{2pt}
	=
	\hspace{2pt}
	\sum_{i=1}^m
	\hspace{2pt}
	p_i
	\hspace{1pt}
	\cdot
	\hspace{1pt}
	\mathsf{Adv}
		^{\mathsf{G}}
		\hspace{1pt}
		[
			\hspace{1pt}
			\mathcal{A}_i
			\hspace{1pt}
		]\hspace{1pt}.
\vspace{0pt}
\end{equation*}
Since $p_1 + \dots + p_m = 1$, we conclude
$
\mathsf{Adv}
	^{\mathsf{G}}
	\hspace{1pt}
	[
		\hspace{1pt}
		\mathcal{A}_i
		\hspace{1pt}
	]
\ge
\mathsf{Adv}
	^{\mathsf{G}}
	\hspace{1pt}
	[
		\hspace{1pt}
		\mathcal{A}
		\hspace{1pt}
	]
$
for some $i \in \{1, \dots, m\}$.
\end{rem}

\subsection{One-more discrete-logarithm ($\mathsf{OMDL}$) hardness}\label{section_omdl_hardness}

The $\mathsf{OMDL}$ problem family
is a parametrized extension of
the discrete-logarithm ($\mathsf{DL}$) problem,
yielding a sequence of increasingly easier related problems.
It was introduced in
\cite{paper_bellare_palacio} and
\cite{paper_bellare_omdl}
as a way to capture design properties
that pragmatically guarantee security under
$\mathsf{DL}$ hardness
while most probably being themselves irreducible to the latter.
Note that reducing security to an easier problem,
i.e., a stronger hardness assumption,
is usually equivalent to assumptions
regarding the black-box adversary,
i.e., a narrower threat model.
This represents a tradeoff between the higher plausibility
of the weaker assumption
and having a security proof at hand,
which may otherwise be intractable.
That is, under the extra assumptions
a formal security proof may become possible,
while a proof under the weaker
assumption may not even exist;
since the solvability of the harder problem
implies solvability of the easier one,
the restricted proof can be regarded as
evidence that security holds
true under the weaker assumption.
In our case, the pragmatic requirement
that cannot be reduced to $\mathsf{DL}$  alone
is the knowledge property
from Section \ref{section_threat_model}.

By \textit{discrete-logarithm \textup{($\mathsf{DL}$)} oracle}
for a cyclic group $\mathbb{G} = \langle g \rangle$
is meant a hypothetical polynomial-time procedure of the form
$z \leftarrow \mathcal{O}_{\mathbb{G}}^{\mathsf{dlog}}(u),
\hspace{2pt} u \in \mathbb{G},$
such that
$u = g ^ z$.
Given $\mathcal{O}_{\mathbb{G}}^{\mathsf{dlog}}$
and an integer $t \ge 1$,
we consider the following problem.

\begin{attack_game}\label{omdl_attack}
\vspace{3pt}
($\mathsf{OMDL}_{\hspace{1pt}\mathbb{G},\hspace{1pt} t-1}$ --
\textit{One-more discrete-logarithm problem})
Given an adversary $\mathcal{A}$ with challenger $\mathcal{C}$,\vspace{2pt}
\begin{itemize}[label=$\circ$,leftmargin=17pt]
	\item
		$\mathcal{C}$ samples $w_i \leftarrow_\$ \mathbb{G},
		\ 0 \le i \le t-1$
		and sends them to $\mathcal{A}$\vspace{5pt}
	\item
		$\mathcal{A}$ outputs $z_0, \dots, z_{t-1}$\vspace{2.5pt}
\end{itemize}
\hspace*{0pt}%
\begin{minipage}{\dimexpr\textwidth-\parindent\relax}%
	\hspace{8pt}$\mathcal{A}$ wins if\hspace{0pt}
	$\bigwedge\limits_{i=0}^{t-1} w_i = g^{z_i}$
	and it has issued at most $t-1$ queries to
	$\mathcal{O}_{\mathbb{G}}^{\mathsf{dlog}}$.
\end{minipage}%
\vspace{3.0pt}
\end{attack_game}

\noindent
The probability that $\mathcal{A}$
solves $\mathsf{OMDL}_{\hspace{1pt}\mathbb{G},\hspace{1pt}t-1}$
is denoted by
\vspace{5pt}
\begin{equation}\label{omdl_advantage_def}
\mathsf{Adv}
	_{\hspace{1pt}\mathbb{G},\hspace{1pt} t-1}
	^{\hspace{1pt}\mathsf{OMDL}}
	\hspace{1pt}
		[\hspace{1pt}
			\mathcal{A}
		\hspace{1pt}]\hspace{1pt}.
\vspace{5pt}
\end{equation}

\noindent
\textit{$(t-1)$-$\mathsf{OMDL}$ hardness in $\mathbb{G}$}
is the assumption that \eqref{omdl_advantage_def}
is negligible for every polynomial-time adversary.
Evidently, $0$-$\mathsf{OMDL}$
is equivalent to $\mathsf{DL}$.
If an adversary solves
$\mathsf{OMDL}_{\hspace{1pt}\mathbb{G},\hspace{1pt} t-1}$
for $t < t^*$,
then it trivially solves
$\mathsf{OMDL}_{\hspace{1pt}\mathbb{G},\hspace{1pt} t^*-1}$,
i.e., $(t^*-1)$-$\mathsf{ODML}$ is generally
an easier problem than $(t-1)$-$\mathsf{OMDL}$.
In particular,
$(t-1)$-$\mathsf{OMDL},\hspace{2pt} t > 1,$
is generally a stronger assumption than
$\mathsf{DL}$.

\section{Security proof}\label{section_security_proof}

\noindent
In this section,
we prove $\mathsf{ORST}$ security against
impersonation attacks (cf. Section \ref{section_security_imp})
under $\mathsf{OMDL}$ hardness
(cf. Section \ref{section_omdl_hardness})
in the random oracle model.
The rationale behind the attack model
is developed throughout Section \ref{section_threat_model}.

Our reduction generalizes the rewinding argument
of the non-distributed case
in order to extract the unknown share $x_j$.
This is a non-trivial generalization.
As indicated by the key-recovery attack
of Section \ref{section_key_recovery_attack},
the extractor comes with a residue
stemming from the $t-1$ degrees of freedom in purturbing a valid proof
with fixed commitments
(cf. Remark \ref{orst_validity_degrees_of_freedom});
it becomes useful only if the logarithms
of the intercepted commitments
are known,
which is the reason for reducing to
$(t-1)$-$\textsf{OMDL}$ hardness.
Moreover, extraction presupposes the fixture of
all but one challenges,
making rewinding useless
in the general threshold setting. We overcome this obstacle
by employing the Local Forking Lemma
(cf. Appendix \ref{section_local_forking_lemma})
and ensuring that the conditions for its applicability
are satisfied. The attack simulator is presented
in Section \ref{section_simulated_impersonation_attack}
and its components are developed in Sections
\ref{section_index_mapping} to
\ref{section_hash_oracles}.


\subsection{Index mapping formalism}\label{section_index_mapping}

Given $J \subset \{1, \dots, n\}$,
we can represent any collection
$\alpha_1, \dots, \alpha_m$ with $|J|=m$
as $\{\beta_i\}_{i \in J}$ using the
$\mathsf{Zip}$ operator, Algorithm \ref{alg_zip}.
Clearly, $\mathsf{Zip}$ preserves the random sampling.

\begin{lemma}\label{zip_lemma}
Given $J \subset \{1, \dots, n\}$, $|J| = m \ge 1$,
the probability distribution
\vspace{5pt}
\begin{equation*}
\{\hspace{1pt}
\mathsf{Zip}\hspace{1pt}(
\alpha_1, \dots, \alpha_m;\hspace{1pt} J\hspace{1pt}):
\hspace{1pt}\alpha_i \leftarrow_\$ A,
\ i = 1, \dots, m
\hspace{1pt}\}
\vspace{5pt}
\end{equation*}
is identical to the distribution
$\{\{\beta_i\}_{i \in J}: \beta_i \leftarrow_\$ A,\ i \in J\}$.
\end{lemma}

\begin{proof}
Follows directly from the definition of $\mathsf{Zip}$.
\end{proof}

\begin{minipage}[t]{0.46\textwidth}
\vspace{0pt}
\begin{algorithm}[H]
    \centering
    \caption{$\mathsf{Zip}\hspace{1pt}
    (\alpha_1, \dots, \alpha_m;
    \hspace{2pt} J\hspace{1pt})$}\label{alg_zip}
    \begin{algorithmic}
    	\vspace{2pt}
    	\State
			$\{i_1, \dots, i_m\} \leftarrow J$\ with
			$i_1 < \dots < i_m$\vspace{3pt}
    	\For{$k = 1, \dots, m$}\vspace{2pt}
			\State
    			$\beta_{i_k} \leftarrow \alpha_k$\vspace{2pt}
		\EndFor
        \State \textbf{return $\{\beta_i\}_{i \in J}$}
    \end{algorithmic}
\end{algorithm}
\vspace{0pt}
\end{minipage}
\hfill
\begin{minipage}[t]{0.46\textwidth}
\vspace{0pt}
\begin{algorithm}[H]
    \centering
    \caption{$\mathsf{Zip}^{-1}\hspace{1pt}
    (\hspace{1pt}\{\beta_i\}_{i \in J})$}\label{alg_zip_inv}
    \begin{algorithmic}
    	\vspace{2pt}
    	\State
			$\{i_1, \dots, i_m\} \leftarrow J$\ with
			$i_1 < \dots < i_m$\vspace{3pt}
    	\For{$k = 1, \dots, m$}\vspace{2pt}
			\State
    			$\alpha_k \leftarrow \beta_{i_k}$\vspace{2pt}
		\EndFor
        \State \textbf{return $\alpha_1, \dots, \alpha_m$}
    \end{algorithmic}
\end{algorithm}\vspace{0pt}
\vspace{0pt}
\end{minipage}

\subsection{Shamir's sharing simulation}\label{section_shamir_sharing_simulation}

Let $y^* \in \mathbb{G}$ and
$x_1^*, \dots, x_{t-1}^* \in \mathbb{Z}_q$ with $t \le n$.
Given $J \subset \{1, \dots n\}$ with $|J| = t-1$
and $j \in \{1, \dots, n\} \setminus J$,
we define
\vspace{5pt}
\begin{equation}\label{shamir_embedding_ref}
(\hspace{1pt}\{x_i\}_{i \in J},\hspace{1pt} y\hspace{1pt})
\leftarrow
\mathcal{D}\hspace{1pt}(
	\hspace{1pt}y^*,
	x_1^*, \dots, x_{t-1}^*
	\hspace{1pt};
	j\hspace{1pt},
	J
)
\vspace{0pt}
\end{equation}
to be Algorithm \ref{alg_shamir_simulation}.
Its properties are summarlized as follows.

\begin{lem}\label{shamir_sharing_simulation_lemma}
%\textup{(\textit{Shamir sharing simulation})}
Let $J \subset \{1, \dots, n\}$, $|J| = t-1$ with $t \le n$,
and $j \in \{1, \dots, n\} \setminus J$.
Given \eqref{shamir_embedding_ref},
there exists a unique $(n, t)$-sharing
$(x_1, \dots, x_n;\hspace{1pt} y)$
such that
\vspace{3pt}
\begin{equation}\label{shamir_sharing_constraint}
\{x_i\}_{i \in J} =
\mathsf{Zip}\hspace{0.75pt}
(\hspace{0.5pt}x_1^*, \dots, x_{t-1}^*)
\ \land
\ y^* = g ^ {x_j}
\vspace{3pt}
\end{equation}
Moreover, the probability distribution
\vspace{5pt}
\begin{equation*}\label{sharing_dist_simulated}
\{\hspace{0.5pt}
(\hspace{0.5pt}\{x_i\}_{i \in J},\hspace{0.5pt} y\hspace{0.5pt}):
\begin{Bmatrix}
(\{x_i\}_{i \in J};\hspace{1pt} y) \leftarrow
\mathcal{D}\hspace{1pt}(
	\hspace{1pt}y^*,
	x_1^*, \dots, x_{t-1}^*
	\hspace{1pt};
	j\hspace{1pt},
	J
)\\[5pt]
y^* \leftarrow_\$ \mathbb{G},
\ \ x_i^* \leftarrow_\$ \mathbb{Z}_q,
\ 1 \le i \le t-1\\[1pt]
\end{Bmatrix}
\}\\[5pt]
\end{equation*}
is identical to
$
\{
\hspace{0.5pt}
(\hspace{0.5pt}\{x_i\}_{i \in J},\hspace{0.5pt} y\hspace{0.5pt}):
(x_1, \dots, x_n;\hspace{1pt} y) \leftarrow D(x),
\hspace{2pt} x \leftarrow_\$ \mathbb{Z}_q
\hspace{0.5pt}
\}
$\hspace{1pt}.
\end{lem}

\begin{proof}
By the elementary properties of interpolation,
$x_1^*, \dots, x_{t-1}^*$ and $y^*$
uniquely determine a sharing
subject to the constraint \eqref{shamir_sharing_constraint},
with the outputs of $\mathcal{D}$
mapping to those of $D$ bijectively.
Equality of distributions follows
from the security property of the Shamir's secret sharing
(cf. Remark \ref{shamir_security}).
\end{proof}

\begin{minipage}{0.96\textwidth}
\begin{algorithm}[H]
    \centering
    \caption{$\mathcal{D}\hspace{1pt}(
	\hspace{1pt}y^*,
	x_1^*, \dots, x_{t-1}^*
	\hspace{1pt};
	j\hspace{1pt},
	J
)$}\label{alg_shamir_simulation}
    \begin{algorithmic}[1]
    	\vspace{4pt}
    	\State
    		Set $y_j \leftarrow y^*$\vspace{6pt}
    	\State
    		$\{x_i\}_{i \in J} \leftarrow
    		\mathsf{Zip}\hspace{0.75pt}
    		(\hspace{0.5pt}x_1^*, \dots, x_{t-1}^*)$\vspace{6pt}
		\State
    		Set $y_i \leftarrow g ^ {x_i},\ i \in J$\vspace{6pt}
    	\State
    		$Q \leftarrow J \cup \{\hspace{1pt}j\hspace{1pt}\}$\vspace{6pt}
    	\State
    		$y \leftarrow \prod_{i \in Q} y_i ^ {\lambda_i}$\vspace{6pt}
		\State
			\textbf{return $\{x_i\}_{i \in J}, y$}\vspace{5pt}
    \end{algorithmic}
\end{algorithm}
\vspace{0pt}
\end{minipage}

\subsection{Hash oracles}\label{section_hash_oracles}

When querying a random oracle $H$
(cf. Algorithm \ref{alg_random_oracle})
in a simulation context,
we usually need to keep track of distinct oracle queries.
Given a finite tape of preallocated hashes
$h = [\hspace{1pt}h_1 \dots, h_m \hspace{1pt}]$
and initially empty lookup tables
$\mathsf{Map}_1$, $\mathsf{Map}_2$,
we define the \textit{hash oracle} $\mathcal{O}^{\mathsf{hash}}$
to be Algorithm \ref{alg_hash_oracle}.

\begin{minipage}[t]{0.46\textwidth}
\begin{algorithm}[H]
    \centering
    \caption{$\mathcal{O}^{\mathsf{hash}}(u)$}\label{alg_hash_oracle}
    \begin{algorithmic}
        \If{$u \not \in \textup{Dom}\hspace{0.5pt}(\mathsf{Map}_1)$}\vspace{2pt}
            \State
            	$c \leftarrow h[\hspace{1pt}\nu\hspace{1pt}]$\vspace{3pt}
        	\State
        		$\mathsf{Map}_1[\hspace{1pt}u\hspace{1pt}]
        		\leftarrow c$\vspace{3pt}
        		\State
        		$\mathsf{Map}_2[\hspace{1pt}u\hspace{1pt}]
        		\leftarrow \nu$\vspace{3pt}
        	\State
        		$\nu \leftarrow \nu + 1$\vspace{0pt}
        \Else
        	\State
        		$c \leftarrow \mathsf{Map}_1
        		[\hspace{1pt}u\hspace{1pt}]$\vspace{0pt}
        \EndIf
        \State \textbf{return $c$}
    \end{algorithmic}
\end{algorithm}
\vspace{0pt}
\end{minipage}
\hfill
\begin{minipage}[t]{0.46\textwidth}
\begin{algorithm}[H]
    \centering
    \caption{$H(u)$}\label{alg_random_oracle}
    \begin{algorithmic}
        \If{$u \not \in \textup{Dom}\hspace{0.5pt}(\mathsf{Map})$}\vspace{2pt}
        	\State
        		$c \leftarrow_\$ C$\vspace{4pt}
        	\State
        		$\mathsf{Map}\hspace{1pt}
        		[\hspace{1pt}u\hspace{1pt}] \leftarrow c$
        \Else
        	\State
        		$c \leftarrow \mathsf{Map}
        		\hspace{1pt}[\hspace{1pt}u\hspace{1pt}]$
        \EndIf
        \State \textbf{return $c$}
    \end{algorithmic}
\end{algorithm}
\vspace{0pt}
\end{minipage}

\noindent
That is, $\mathcal{O}^{\mathsf{hash}}$
operates like a random oracle with lookup table $\mathsf{Map}_1$
but draws hashes
from $h$ instead of sampling them uniformly;
upon inserting a fresh hash to $\mathsf{Map}_1$,
it takes care to
(i) update the tape pointer so that
the next predefined hash be available on demand and
(ii) insert the current pointer value to $\mathsf{Map}_2$
so that the respective query can be tracked by order.
Evidently, if $h_1, \dots, h_n$
are uniformly sampled from the codomain of $H$,
then $\mathcal{O}^{\mathsf{hash}}$
cannot be distinguished from $H$.
We state this remark formally for the sake of reference.

\begin{lem}\label{lemma_random_oracle_simulation}
\textup{(\textit{Random oracle simulation})}
Given a random oracle $H$ with codomain $C$
and initially empty lookup table $\mathsf{Map}$,
initialize a hash oracle $\mathcal{O}^{\mathsf{hash}}$
over an empty tape $h$ of size $m \ge 1$
and initially empty lookup tables $\mathsf{Map}_1$ and $\mathsf{Map}_1$.
For any distinct elements $u_1, \dots, u_m$,
the probability distribution
\vspace{5pt}
\begin{equation*}
\vspace{5pt}
\{\hspace{0.5pt}(c_1, \dots, c_m):
\ c_\nu \leftarrow \mathcal{O}^{\mathsf{hash}}(u_\nu),
\ h\hspace{0.5pt}
	[
		\hspace{1pt}
		\nu
		\hspace{1pt}
	]
	\leftarrow_\$
	C,
\ \nu = 1, \dots, m\hspace{0.5pt}\}
\end{equation*}
is identical to the distribution
$
\{\hspace{0.5pt}(c_1, \dots, c_m):\hspace{0.50pt}
c_\nu \leftarrow H(u_\nu),
\ \nu = 1, \dots, m\hspace{0.5pt}\}
$.
\end{lem}

\begin{proof}
Follows directly from the definition of $\mathcal{O}^{\mathsf{hash}}$.
\end{proof}

\subsection{Simulated impersonation attack}\label{section_simulated_impersonation_attack}

We define an algorithm
$
\mathcal{S}
		\hspace{.5pt}
		[
			\hspace{0.5pt}
			\mathcal{A}
			\hspace{1pt}
		]
		\hspace{0.5pt}
$
that simulates Game \ref{orst_attack_impersonation}
for the adversary $\mathcal{A}$,
provided that $H$ is modelled as a random oracle.
Roughly speaking,
$
\mathcal{S}
		\hspace{.1pt}
		[
			\hspace{0.1pt}
			\mathcal{A}
			\hspace{0.5pt}
		]
		\hspace{0.5pt}
$
accepts
the ingredients of $\mathcal{A}$'s view and outputs
the proof fabricated by $\mathcal{A}$ along with
a relevant success index.
The simulation is perfect meaning that,
if run with uniform input,
the probability of success equals
the adversary's advantage of
winning the real game.

More accurately, given a black-box adversary $\mathcal{A}$
to game $\mathsf{ORST}_{\hspace{1pt}\mathbb{G}, n, t}$,
the desired simulation is a wrapper of $\mathcal{A}$ of the form
\vspace{5pt}
\begin{equation*}
	(
		\hspace{0.5pt}
		k,
		\hspace{0.5pt}
		(
			\hspace{0.5pt}
			j,
			\hspace{0.5pt}
			\sigma
		)
		\hspace{0.5pt}
	)
	\hspace{2pt}
	\leftarrow
	\hspace{2pt}
	\mathcal{S}
		\hspace{.5pt}
		[
			\hspace{0.5pt}
			\mathcal{A}
			\hspace{1pt}
		]
		\hspace{1pt}
		(
			\hspace{1pt}
			y ^*,
			\hspace{1pt}
			x_1^*, \dots, x_{t-1}^*,
			\hspace{1pt}
			w_1, \dots, w_{t-1};
			\hspace{1pt}
			h_1, \dots, h_m
		)\hspace{1pt},
\vspace{5pt}
\end{equation*}
arranging its input values appropriately
in order to emulate $\mathcal{A}$'s execution environment.
The values $y^*, x_1^*, \dots, x_{t-1}^*$
will uniquely determine the attacked $(n, t)$-sharing,
yielding the corrupted shares in the process.
Similarly, $w_1, \dots, w_{t-1}$ will be used
as the intercepted commitments.
Next, the embedded replica of $\mathcal{A}$
consumes its view in order to fabricate
a purportedly valid proof $\sigma$
with the difference that,
instead of invoking $H$ directly,
it queries an embedded hash oracle
$\mathcal{O}^{\mathsf{hash}}$
with tape $h_1, \dots, h_{m}$
(cf. Section \ref{section_hash_oracles}).
If needed, $\mathcal{A}$ may be reprogrammed
without loss of generality
to query hashes for all the commitments it sees
(including the one fabricated by itself),
so that $m \ge 1$.
Finally, an $\mathsf{ORST}$-verifier $\mathcal{V}$
is included with access to the same hash oracle for
verifying the output of the embedded adversary.
The exact procedure is shown in Algorithm \ref{alg_attack_simulator}.

The hash oracle $\mathcal{O}^{\mathsf{hash}}$
is first initialized with tape
$[\hspace{0.5pt}h_1, \dots, h_m\hspace{0.5pt}]$
and empty lookup tables.
After $\mathcal{A}$ makes its attack statement,
the virtual challenger simulates the unique sharing
$(x_1, \dots, x_n;\hspace{2pt} y) \leftarrow D(x),
\hspace{2pt} x \leftarrow \mathbb{Z}_q$
subject to the constraint \eqref{shamir_sharing_constraint};
in particular, $x_j = \log y^*$.
It then generates commitments
$\{u_i\}_{i \in J}$ and feeds them
along with $y$ and $\{x_i\}_{i \in J}$
to $\mathcal{A}$, who proceeds
to impersonation
and generates a proof of the expected form,
i.e., $Q = J \cup \{\hspace{0.5pt}j\hspace{0.5pt}\}$.
Observe that the oracle queries are implicitly issued
at step 5, including the challenges
$c_i \leftarrow \mathcal{O}^{\mathsf{hash}}(u_i),\hspace{2pt} i \in Q$,
which are collected and attached to the fabricated
proof for later usage (steps 7-9).
We also locate the unique $k \in \{1, \dots, m\}$
for which $c_j = h\hspace{1pt}[\hspace{1pt}k\hspace{1pt}]$
(step 10), indicating that the fabricated commitment $u_j$
was submitted at the $k$-th distinct query.
If $\mathcal{A}$ succeeds in its impersonation attempt,
the simulation returns $(k, (j, \sigma))$; otherwise, it
returns $(\hspace{1pt}0, (j, \sigma))$
to indicate failure.

\begin{figure}[H]
 \centering
 \begin{overpic}[scale=0.8]{reduction.pdf}
  \put (89,62.50) {$\mathcal{S}\hspace{1pt}[\hspace{1pt}\mathcal{A}\hspace{1pt}]$}
  %\put (20,72.50) {$y^*, \{x_i\}_{i \in J}, \{u_i\}_{i \in J}, h_1, \dots, h_m$}
  \put (14.75,75.6) {$y^*, x_1^*, \dots, x_{t-1}^*,
  w_1, \dots, w_{t-1}, h_1, \dots, h_m$}
  %\put (15.0,62.0) {$y^*, \{x_i\}_{i \in J}$}
  \put (11.00,64.50) {$y^*, x_1^*, \dots, x_{t-1}^*$}
  %\put (50,62.0) {$\{x_i\}_{i \in J}$}
  \put (17.0,53.0) {$\mathcal{D}$}
  \put (33,58.50) {$j, J$}
  %\put (35.0,50.4) {$\{x_i\}_{i \in J},\hspace{2pt} y$}
  \put (30.0,52.9) {$y,\hspace{1pt} \{x_i\}_{i \in J}$}
  \put (62,57) {$\mathcal{A}$}
  \put (59,49.5) {$\mathcal{\bar{A}}$}
  \put (30.5,43.5) {$\{u_{i}\}_{i \in J}$}
  \put (16.50,41.50) {$\mathsf{Zip}$}
  \put (7,38) {$\mathcal{C}$}
  % \put (09,37) {$\mathcal{C}$}
  \put (85.00,47.50) {$\mathcal{O}^{\mathsf{hash}}$}
  \put (72,52.50) {$u_i$}
  \put (72,46.50) {$c_i$}
  \put (86.60,34.0) {$u_i$}
  \put (93.60,34.0) {$c_i$}
  \put (70,27.00) {$\sigma$}
  \put (17,25.90) {$\dots$}
  \put (27,25.90) {$\dots$}
  \put (37,25.90) {$\dots$}
  \put (07,22.35) {$h_1$}
  \put (12,22.35) {$h_2$}
  \put (20,22.35) {$\cdots$}
  \put (28,22.35) {$h_k$}
  \put (33,22.35) {$\cdots$}
  \put (38,22.35) {$h_m$}
  \put (88.0,22.5) {$\mathcal{V}$}
  \put (68.0,03.5) {$k$}
  \put (71.5,03.5) {$j$}
  \put (74.9,03.5) {$\sigma$}
 \end{overpic}
\caption{The
$\mathsf{ORST}
	_{\hspace{1pt}\mathbb{G}, n, t}
	^{\hspace{1pt}\mathbf{imp}}
$
simulator}
\label{fig_attack_simulator}
\end{figure}

\begin{prop}\label{orst_simulated_impersonation_attack_prop}
\textup{($\mathsf{ORST}
	_{\hspace{1pt}\mathbb{G}, n, t}
	^{\hspace{1pt}\mathbf{imp}}
$
-- \textit{Perfect simulation})}
If $H$ is modelled as a random oracle, then
$
\mathcal{S}
		\hspace{.5pt}
		[
			\hspace{0.5pt}
			\mathcal{A}
			\hspace{1pt}
		]
$
simulates Game \textup{\ref{orst_attack_impersonation}} perfectly
if invoked with uniformly random input,
in the sense that the real and simulated game executions
are indistinguishable from the adversary's viewpoint.
More accurately, the probability distribution of $\mathcal{A}$'s view
in the real attack game
is identical to the distribution of $\mathcal{\bar{A}}$'s
input in the invocation
\vspace{6pt}
\begin{equation}\label{orst_attack_simulated}
\begin{split}
(k, (j, \sigma)) \hspace{2pt}\leftarrow\hspace{2pt} \mathcal{S}
		\hspace{.5pt}
		[
			\hspace{0.5pt}
			\mathcal{A}
			\hspace{1pt}
		]
		\hspace{1pt}
		(
			\hspace{1pt}
			y ^*,
			\hspace{1pt}
			x_1^*, \dots, x_{t-1}^*,
			\hspace{1pt}
			w_1, \dots, w_{t-1};
			\hspace{1pt}
			h_1, \dots, h_m
		),\\[5pt]
y^* \leftarrow_\$ \hspace{3pt}\mathbb{G},
\ \ \ x_i^* \leftarrow_\$ \mathbb{Z}_q,
\ \ \ w_i \leftarrow_\$ \mathbb{G},
\ \ \ 1 \le i \le t - 1,\\[5pt]
h_\nu \leftarrow_\$ \mathbb{Z}_q,\ 1 \le \nu \le m\\[6pt]
\end{split}
\end{equation}
In the context of this simulation, if $\mathcal{\bar{A}}$
succeeds in its impersonation attempt,
i.e., $k \ge 1$, the input value $h_k$ maps
to $c_j \equiv H(u_j)$ of the real game execution.
\end{prop}

\begin{proof}
In the real game execution, the adversarial view consists of
the corrupted shares $\{x_i\}_{i \in J}$
along with the combined public key $y$,
the intercepted commitments $\{u_i\}_{i \in Q}$
and the hashes queried during the impersonation phase.
These three blocks are independent
from each other; clearly, the first and second blocks are
independent, while the third block is independent from the others
because $H$ is a random oracle.
It thus suffices to check that the respective blocks
have identical distributions in the simulated execution
\eqref{orst_attack_simulated}.
The first block is perfectly simulated
due to Lemma \ref{shamir_sharing_simulation_lemma}.
The second block is also perfectly simulated
due to Lemma \ref{zip_lemma}.
Finally, the third block is perfectly simulated
due to Lemma \ref{lemma_random_oracle_simulation}.
The fact that
$h_k = h\hspace{1pt}[\hspace{1pt}k\hspace{1pt}]$
corresponds to $H(u_j)$
follows directly from step 10, Algorithm \ref{alg_attack_simulator}.
\vspace{5pt}
\end{proof}

\noindent
We denote by
$
\mathsf{acc}\hspace{0.5pt}(
	\mathcal{S}
	\hspace{0.5pt}
	[
		\hspace{0.5pt}
		\mathcal{A}
		\hspace{1pt}
	]
	\hspace{1pt})
$
the probability that the embedded adversary
succeeds in the context of a simulated attack
when run with uniformly random input.
This is related to the real adversarial advantage
as follows.

\begin{cor}\label{equality_intermediate}
Given an adversary $\mathcal{A}$
for Game \textup{\ref{orst_attack_impersonation}},
there holds
\vspace{5pt}
\begin{equation}
	\mathsf{acc}\hspace{0.5pt}(
		\mathcal{S}
		\hspace{0.5pt}[
			\hspace{1pt}
			\mathcal{A}
			\hspace{1pt}
		]\hspace{0.5pt}
	)
	\hspace{2pt}
	=
	\hspace{2pt}
	\mathsf{Adv}
		_{\hspace{1pt}\mathbb{G}, n, t}
		^{\hspace{1pt}\mathsf{ORST}}\hspace{0.5pt}
		[
			\hspace{1pt}
			\mathcal{A}
			\hspace{1pt}
		]
\vspace{5pt}
\end{equation}
\end{cor}

\begin{proof}
Direct consequence of Proposition
\ref{orst_simulated_impersonation_attack_prop}.
\end{proof}

\begin{minipage}{0.94\textwidth}
\begin{center}
\begin{algorithm}[H]
    \centering
    \caption{$\mathcal{S}
		\hspace{.5pt}
		[
			\hspace{0.5pt}
			\mathcal{A}
			\hspace{1pt}
		]
		\hspace{1pt}
		(
			\hspace{1pt}
			y ^*,
			\hspace{1pt}
			x_1^*, \dots, x_{t-1}^*,
			\hspace{1pt}
			w_1, \dots, w_{t-1};
			\hspace{1pt}
			h_1, \dots, h_m
		)$}\label{alg_attack_simulator}
    \begin{algorithmic}[1]
    	\vspace{4pt}
    	\State
    		$h \leftarrow
    		[\hspace{1pt}h_1, \dots, h_m\hspace{1pt}],
    		\ \nu \leftarrow 1,
    		\ \mathsf{Map}_1 = \varnothing,
    		\ \mathsf{Map}_2 = \varnothing$
    		\hspace{14pt}// \textit{Setup
    		$\mathcal{O}^{\mathsf{hash}}$}\vspace{5pt}
    	\State
    		$(\hspace{1pt}j, J\hspace{1pt}) \leftarrow \mathcal{A}_0
    		\hspace{0.5pt}(\hspace{1pt}\cdot\hspace{1pt})$
    		\hspace{160pt}// \textit{Attack statement}\vspace{5pt}
    	\State
    		$(\hspace{1pt}\{x_i\}_{i \in J},\hspace{1pt} y\hspace{1pt})
			\leftarrow
			\mathcal{D}\hspace{1pt}(
			\hspace{1pt}y^*,
			x_1^*, \dots, x_{t-1}^*
			\hspace{1pt};
			j\hspace{1pt},
			J
			\hspace{1pt}
			)$
    		\hspace{49pt}// \textit{Corruption}\vspace{6pt}
    	\State
    		$\{u_i\}_{i \in J} \leftarrow
    		\mathsf{Zip}\hspace{0.75pt}
    		(\hspace{0.5pt}w_1, \dots, w_{t-1})$
    		\hspace{99pt}// \textit{Interception}\vspace{6pt}
		\State
			$\{(u_i, s_i)\}_{i \in Q} \leftarrow
			\mathcal{\bar{A}}\hspace{1pt}(\hspace{1pt}
			y, \{x_i\}_{i \in J}, \{u_i\}_{i \in J}\hspace{1pt})$
			\hspace{56pt}// \textit{Impersonation}\vspace{7pt}
		\State
			$res
			\hspace{2pt}
			\leftarrow
			\hspace{2pt}
			\mathcal{V}\hspace{1pt}(\hspace{1pt}y,
			\{(u_i, s_i)\}_{i \in Q})$\vspace{4pt}
		\For{$i \in Q$}\vspace{2pt}
			\State
				$c_i \leftarrow \mathsf{Map}_1
				[\hspace{1pt}u_i\hspace{1pt}]$\vspace{2pt}
		\EndFor
		\State
			$\sigma \leftarrow \{(u_i, c_i, s_i)\}_{i \in Q}$\vspace{5pt}
		\State
			$k \leftarrow \mathsf{Map}_2[\hspace{1pt}
			u_j\hspace{1pt}]$\vspace{4pt}
		\If{$res = \mathsf{true}$}\vspace{3pt}
			\State
				\textbf{return $(
					\hspace{0.5pt}
					k,
					\hspace{0.5pt}
					(
						\hspace{0.5pt}
						j,
						\hspace{0.5pt}
						\sigma
					)
					\hspace{0.5pt}
				)$}
		\EndIf
		\State
			\textbf{return $(
				\hspace{0.5pt}
				0,
				\hspace{0.5pt}
				(
					\hspace{0.5pt}
					j,
					\hspace{0.5pt}
					\sigma
				)
				\hspace{0.5pt}
			)$}\vspace{3pt}
    \end{algorithmic}
\end{algorithm}
\end{center}
\vspace{5pt}
\end{minipage}

\subsection{Local fork and extraction}\label{section_extractability}

In the non-distributed case $t=1$,
the simulator
$\mathcal{S}\hspace{0.5pt}[\hspace{0.5pt}\mathcal{A}\hspace{1pt}]$
yields the execution environment of the rewindable adversary
$\mathcal{A}$ that is usually employed to
reduce the security of ordinary Schnorr identification
to $\mathsf{DL}$ hardness in the random oracle model.
In the distributed case $t \ge 1$, the extractor is generalized as
\eqref{orst_key_recovery},
provided that the forked attack runs with the same hashes
except for $c_j \leftarrow H(u_j)$.
This implies that the rewinding argument
cannot be effective in the threshold setting;
indeed, resetting the attack before
$\mathcal{A}$ sends $u_j$ does not
guarantee that subsequent oracle responses remain the same
and, in fact, they differ almost certainly.
However, when invoking
$\mathcal{S}\hspace{0.5pt}[\hspace{0.5pt}\mathcal{A}\hspace{1pt}]$
we predefine the hashes $h_1, \dots, h_m$
returned by the embedded oracle in respective order,
which allows to run again the simulator with the same hashes
except for $c_j = h_k$.
In this case, the Local Forking Lemma
(cf. Appendix \ref{section_local_forking_lemma})
becomes applicable in place of rewinding
(cf. \cite{paper_bellare_musig} or Reset Lemma \cite{paper_bellare_palacio}),
provided that $\mathcal{A}$
is deterministic.
Recall that the local fork of
$\mathcal{S}\hspace{0.5pt}[\hspace{0.5pt}\mathcal{A}\hspace{1pt}]$
is an algorithm of the form
\vspace{5pt}
\begin{equation*}
(
	\vspace{1pt}
	b,
	\vspace{1pt}
	\mathsf{out}
	\hspace{0.5pt}
)
\hspace{2pt}
\leftarrow
\hspace{2pt}
\mathsf{LocalFork}_{
		\hspace{1pt}
    	\mathcal{S}\hspace{0pt}[
    		\hspace{0pt}
    		\mathcal{A}
    		\hspace{0pt}
    	]
    }
	(
   		\hspace{1pt}
		y ^*,
		\hspace{1pt}
		x_1^*, \dots, x_{t-1}^*,
		\hspace{1pt}
		w_1, \dots, w_{t-1}
		\hspace{1pt}
   	)
\vspace{5pt}
\end{equation*}
(cf. Appendix \ref{section_local_forking_lemma})
operating as follows.
If the embedded adversary $\mathcal{A}$
succeeds in its first
impersonation attempt,
the fork reexecutes the simulation
with the same input values except
for the $k$-th predefined hash,
which is afresh uniformly sampled as $h_k^*$;
otherwise, the fork aborts.
When the second simulation completes,
the fork checks if $\mathcal{A}$
succeeds again under the condition $h_k^* \neq h_k$;
in this case, it returns the successive outputs
$\tau \equiv (\hspace{0.5pt}j, \sigma)$
and $\tau^* \equiv (\hspace{0.5pt}j, \sigma^*)$
of both simulations; otherwise, it aborts.

Evidently,
$
\mathsf{forkAcc}
\hspace{0.5pt}
(
	\mathcal{S}
	[
		\hspace{0.5pt}
		\mathcal{A}
		\hspace{1pt}
	]
	\hspace{0.5pt}
)
$
expresses here the probability that $\mathcal{A}$
succeeds both in its first and forked impersonation attempt
when consuming the same uniformly random
input (except for the $k$-th distinct hash).
The consecutive outputs are correlated as follows.

\begin{prop}\label{orst_extractability_prop}
\textup{(\textit{Local fork and extraction})}
Let $\mathcal{A}$ be a deterministic adversary of
Game \textup{\ref{orst_attack_impersonation}}
and
$\tau = (\hspace{0.5pt}j, \sigma),
\hspace{2pt}\tau^* = (\hspace{0.5pt}j, \sigma^*)$
be outputs of a non-aborting execution
\vspace{5pt}
\begin{equation*}
(
	\vspace{1pt}
	1,
	\vspace{1pt}
	(
		\hspace{0.5pt}
		\tau,
		\tau^*
		\hspace{0.5pt}
	)
	\hspace{0.5pt}
)
\hspace{2pt}
\leftarrow
\hspace{2pt}
\mathsf{LocalFork}_{
		\hspace{1pt}
    	\mathcal{S}\hspace{0pt}[
    		\hspace{0pt}
    		\mathcal{A}
    		\hspace{0pt}
    	]
    }
	(
   		\hspace{1pt}
		y ^*,
		\hspace{1pt}
		x_1^*, \dots, x_{t-1}^*,
		\hspace{1pt}
		w_1, \dots, w_{t-1}
		\hspace{1pt}
   	)
\vspace{5pt}
\end{equation*}
Then $\sigma,\hspace{1pt}\sigma^*$ are of the form
$\{(u_i, c_i, s_i)\}_{i \in Q}, \{(u_i, c_i^*, s_i^*)\}_{i \in Q}$
and subject to the constraint
\vspace{5pt}
\begin{equation}\label{orst_forked_challenges}
c_j \neq c_j^*
\ \land
\ c_i = c_i^*,\hspace{2pt}
\forall i \in Q \setminus \{\hspace{0.5pt}j\hspace{0.5pt}\}
\hspace{0.5pt}.
\vspace{5pt}
\end{equation}
Moreover, the extraction formula
\vspace{5pt}
\begin{equation}\label{orst_extraction}
x_j
\hspace{2pt}
=
\hspace{2pt}
\frac{s_j - s_j^*}{c_j - c_j^*}
\hspace{2pt}
+
\hspace{2pt}
\frac{1}{\mu_j} \sum_{i \in J}
\hspace{2pt}
\Big(
	\mu_i (s_i - r_i - c_i x_i) -
	\mu_i^* (s_i^* - r_i - c_i x_i)
\Big)
\vspace{5pt}
\end{equation}
holds true for $x_j \equiv \log y^*$, where
$r_i \equiv \log u_i$
and 
$\{\mu_i\}_{i \in Q}$, $\{\mu_i^*\}_{i \in Q}$
are the weights of
$\sigma$ and $\sigma^*$ respectively.
\end{prop}

\begin{proof}
Let $\sigma = \{(u_i, c_i, s_i)\}_{i \in Q},\hspace{2pt}
\sigma^* = \{u_i^*, c_i^*, s_i^*\}_{i \in Q},$ so that
$u_i^* = u_i,\hspace{2pt}\forall i \neq j$.
Fabricating the $j$-th commitment completes
before submitting it to the hash oracle
and is thus unaffected by the $k$-th hash.
Since $\mathcal{A}$ is deterministic and its view is
the same in both simulations except for the $k$-th hash,
we conclude that $u_j = u_j^*$.
The constraint regarding challenges follows because
$c_j^* = h_k^* \neq h_k = c_j$
and the rest challenges are drawn from $\{h_\nu\}_{\nu \neq k}$.
We proceed to extraction.
Since both $\sigma$, $\sigma^*$ are valid, Corollary
\ref{orst_validity_above_prop} implies
\vspace{5pt}
\begin{equation}\label{aux_mus}
\sum_{i \in Q} \mu_i (s_i - r_i - c_i x_i) = 0\hspace{1pt},
\hspace{12pt}
\sum_{i \in Q} \mu_i^* (s_i^* - r_i - c_i^* x_i) = 0\hspace{1pt}.
\vspace{5pt}
\end{equation}
\noindent
Since $c_i = c^*_i$ for $i \neq j$,
by definition of weights (cf. Def. \ref{orst_weights_definition}) we get
$\mu_j = \mu^*_j\hspace{1pt}$.
Substracting terms in \eqref{aux_mus} and applying this remark yields
\vspace{5pt}
\begin{equation*}
\mu_j (s_j - s_j^* - (c_j - c_j^*)\hspace{1pt} x_j)
\hspace{2pt}
+
\hspace{1pt}
\sum_{i \in J}\hspace{1pt}
(
\hspace{1pt}
\mu_i (s_i - r_i - c_i x_i)
-
\mu_i^* (s_i^* - r_i - c_i x_i)
\hspace{1pt}
)
=
0\hspace{1pt}.
\vspace{5pt}
\end{equation*}
Extraction follows because $c_j - c_j^* \neq 0$.
\vspace{0pt}
\end{proof}

\subsection{Main theorem}\label{section_main_theorem}

\noindent
% We proceed to the final reduction argument.

\begin{thm}\label{theorem_orst_security}
\textup{(\textsf{ORST} --
\textit{Security against impersonation attacks})}
%Given a pair of threshold parameters $(n, t)$,
$\mathsf{ORST}_{\hspace{1pt}\mathbb{G}, n, t}$
is secure against impersonation attacks
under $(t-1)$-$\mathsf{OMDL}$ hardness
in the random oracle model.
In particular, if $H$ is modelled as a random oracle,
for every polynomial-time adversary $\mathcal{A}$ that attacks
$\mathsf{ORST}
	_{\hspace{1pt}\mathbb{G},\hspace{0.5pt} n,\hspace{0.5pt} t}
	^\mathbf{\hspace{1pt}imp}
$
there exists a polynomial-time
adversary $\mathcal{A}^*$ that solves
$\mathsf{OMDL}
	_{\hspace{1pt}\mathbb{G},\hspace{0.5pt} t-1}
$
with
\vspace{5pt}
\begin{equation}\label{orst_security_bound}
	\mathsf{Adv}
		_{\hspace{1pt}\mathbb{G},\hspace{1pt} t-1}
		^{\hspace{1pt}\mathsf{OMDL}}
		\hspace{1pt}
		[
			\hspace{0.5pt}
			\mathcal{A}^*
			\hspace{0.5pt}
		]
	\hspace{2pt}
	\ge
	\hspace{2pt}
	\frac{1}{q_{\mathsf{ro}} + 1}
	\hspace{2pt}
	\mathsf{Adv}
		_{\hspace{1pt}\mathbb{G}, \hspace{0.5pt}n, \hspace{0.5pt}t}
		^{\hspace{1pt}\mathsf{ORST}}
		\hspace{0.5pt}
		[
			\hspace{0.5pt}
			\mathcal{A}
			\hspace{1pt}
		] ^ {\hspace{1pt}2},
\vspace{5pt}
\end{equation}
where $q_\mathsf{ro} + 1$ is the number of distinct queries
issued by $\mathcal{A}$ to the random oracle.
\end{thm}

\begin{proof}
We construct $\mathcal{A}^*$ as a wrapper of
$
\mathsf{LocalFork}_{
		\hspace{1pt}
    	\mathcal{S}\hspace{0pt}[
    		\hspace{0pt}
    		\mathcal{A}
    		\hspace{0pt}
    	]
    }
$;
after forking a successful impersonation attack,
the wrapper should be able to recover the unknown share
by issuing at most $t-1$ discrete-logarithm queries
and then use it to solve
$\mathsf{OMDL}_{\hspace{1pt}\mathbb{G},\hspace{0.5pt} t-1}$
with comparable chances.

We may assume without loss of generality that $\mathcal{A}$
is deterministic (cf. Remark \ref{rem_deterministic_adversaries}).
When given $w_0, \dots, w_{t-1}$
by its challenger
(cf. Game \ref{omdl_attack}),
$\mathcal{A}^*$ operates as in Algorithm \ref{alg_omdl_adversary}.
Note that $\mathcal{A}^*$
aborts if the fork aborts,
i.e., unless both impersonation attacks by $\mathcal{A}$
are successful;
otherwise, the fork fulfills the conditions of
Proposition \ref{orst_extractability_prop}
and the proofs fabricated by $\mathcal{A}$
are as shown at steps 7 and 8.
By definition of
$\mathcal{S}\hspace{0pt}[
 	\hspace{0pt}
    \mathcal{A}
    \hspace{0pt}
    ]
$,
the attacks of step 3
unfold against the sharing $(x_1, \dots, x_n;\hspace{2pt} y)$
that is determined by the constraint
\vspace{5pt}
\begin{equation}\label{mt_1}
\{x_i\}_{i \in J} =
\mathsf{Zip}\hspace{0.75pt}
(\hspace{0.5pt}x_1^*, \dots, x_{t-1}^*)
\ \land
\ y^* = g ^ {x_j}
\vspace{5pt}
\end{equation}
(cf. Lemma \ref{shamir_sharing_simulation_lemma}).
Similarly, the intercepted commitments
$u_i,\hspace{2pt} i \in J,$
comprise of the input values $w_1, \dots, w_{t-1}$;
in particular,
\vspace{3pt}
\begin{equation}\label{mt_2}
\{u_i\}_{i \in J} =
\mathsf{Zip}\hspace{0.75pt}
(\hspace{0.5pt}w_1, \dots, w_{t-1})
\vspace{3pt}
\end{equation}
(cf. Algorithm \ref{alg_attack_simulator}, step 4).
In steps 9-14, $\mathcal{A}^*$ computes the
parameters that are needed for the extraction of step 15.
The compromised shares are recomputed at step 13 using the first
part of constraint \eqref{mt_1}, while the logarithms
of $u_i,\hspace{2pt} i \in J,$ are retrieved
at step 14
by submitting them to the $\mathsf{DL}$ oracle.
Since $y^* = w_0$,
Proposition \ref{orst_extractability_prop} ensures
that the computation of step 15 yields
$z_0 = \log w_0$.
Similarly, due to \eqref{mt_2},
step 17 yields
$z_i = \log w_i,\hspace{2pt} 1 \le i \le t-1$.
In short,
$z_0, z_1, \dots, z_{t-1}$ is the solution
to the original problem instance and $\mathcal{A}^*$
has issued at most $t-1$ distinct queries
to the $\mathsf{DL}$ oracle.

In short, $\mathcal{A}^*$ solves
$\mathsf{OMDL}
	_{\hspace{1pt}\mathbb{G},\hspace{0.5pt} t-1}$
exactly if it does not abort.
Since $w_0, w_1, \dots, w_{t-1}$
are uniformly sampled by its challenger,
$\mathcal{A}^*$'s advantage is equal to the probability that
\vspace{5pt}
\begin{equation*}
    		(
				\vspace{1pt}
				b,
				\vspace{1pt}
				\mathsf{out}
				\hspace{0.5pt}
			)
			\hspace{2pt}
			\leftarrow
			\hspace{2pt}
    		\mathsf{LocalFork}_{
				\hspace{1pt}
    			\mathcal{S}
    			\hspace{0pt}[
    				\hspace{0pt}
    				\mathcal{A}
    				\hspace{0pt}
    			]
    		}
			(
   				\hspace{1pt}
				y ^*,
				\hspace{1pt}
				x_1^*, \dots, x_{t-1}^*,
				\hspace{1pt}
				w_1, \dots, w_{t-1}
   			)
\vspace{5pt}
\end{equation*}
\noindent
of step 3 is a non-aborting execution or, in other words,
\vspace{5pt}
\begin{equation*}
	\mathsf{Adv}
		_{\hspace{1pt}\mathbb{G},\hspace{1pt} t-1}
		^{\hspace{1pt}\mathsf{OMDL}}
		\hspace{1pt}
		[
			\hspace{0.5pt}
			\mathcal{A}^*
			\hspace{0.5pt}
		]
	\hspace{2pt}
	=
	\mathsf{forkAcc}
		\hspace{0.5pt}
		(
			\mathcal{S}
			\hspace{0.5pt}
			[
				\hspace{0.5pt}
				\mathcal{A}
				\hspace{0.5pt}
			]
			\hspace{0.5pt}
		)\hspace{1pt}.
\vspace{5pt}
\end{equation*}

\noindent
Let $m = q_{\mathsf{ro}} + 1$ be the number of distinct
queries issued by $\mathcal{A}$ to $\mathcal{O}^{\mathsf{hash}}$
in the context of
$\mathcal{S}\hspace{0.5pt}[\hspace{0.5pt}\mathcal{A}\hspace{0.5pt}]$.
The desired inequality follows from the
Local Forking Lemma
and Corollary \ref{equality_intermediate}.
\end{proof}

\begin{minipage}{0.97\textwidth}
\begin{algorithm}[H]
    \centering
    \caption{$\mathcal{A}^*\hspace{1pt}(
    	w_0, w_1, \dots, w_{t-1})$}\label{alg_omdl_adversary}
    \begin{algorithmic}[1]
    	\vspace{4pt}
    	\State
    		Set $y^* \leftarrow w_0$
    		\vspace{6pt}
    	\State
    		Set $x_i^* \leftarrow_\$ \mathbb{Z}_q,\hspace{2pt}
    		1 \le i \le t-1$
    		\vspace{6pt}
    	\State
    		$
    		(
				\vspace{1pt}
				b,
				\vspace{1pt}
				\mathsf{out}
				\hspace{0.3pt}
			)
			\hspace{2pt}
			\leftarrow
			\hspace{2pt}
    		\mathsf{LocalFork}_{
				\hspace{1pt}
    			\mathcal{S}
    			\hspace{0pt}[
    				\hspace{0pt}
    				\mathcal{A}
    				\hspace{0pt}
    			]
    		}
			(
   				\hspace{1pt}
				y ^*,
				\hspace{1pt}
				x_1^*, \dots, x_{t-1}^*,
				\hspace{1pt}
				w_1, \dots, w_{t-1}
   			)$
    		\vspace{5pt}
    	\If{$b = 0$}\vspace{5pt}
			\State
				\textbf{return $\bot$}\vspace{5pt}
		\EndIf
		\State
			Parse $
				(
					\hspace{0.5pt}
					\tau,
					\tau^*
					\hspace{0.2pt}
				)
				\leftarrow
				\mathsf{out}
			$\vspace{5pt}
		\State
			Parse $
			(
				\hspace{1pt}
				j,
				\hspace{1pt}
				\{
					(
						\hspace{0.2pt}
						u_i\hspace{1pt},
						c_i\hspace{1pt},
						s_i\hspace{1pt}
					)
				\}_{i \in Q}
				\hspace{0pt}
			)
			\leftarrow
			\tau
			$
			\vspace{6pt}
		\State
			Parse
			$
			(
				\hspace{1pt}
				j,
				\hspace{1pt}
				\{
					(
						\hspace{0.2pt}
						u_i,
						c_i^*,
						s_i^*
						\hspace{0.2pt}
					)
				\}_{i \in Q}
				\hspace{0pt}
			)
			\leftarrow
			\tau^*
			$
			\vspace{6pt}
    	\State
    		$J \leftarrow Q \setminus
    		\{\hspace{0.5pt} j \hspace{0.5pt}\}$
    		\vspace{6pt}
    	\State
    		Compute the Lagrange interpolation coefficients
    		$\{\lambda_i\}_{i \in Q}$
    		\vspace{6pt}
    	\State
    		Compute
    		\begin{equation*}
    			\hspace{-12pt}\mu_j \leftarrow \lambda_j
    			\prod_{i \in J} c_i
    		\end{equation*}
    		\vspace{-7pt}
    	\For{$i \in J$, compute}
    		\vspace{2pt}
    		\begin{equation*}
    			\mu_i \leftarrow \lambda_i
    			\prod_{k \in Q \setminus \{i\hspace{0.2pt}\}} c_k,
    		\hspace{15pt}
    			\mu_i^* \leftarrow \lambda_i
    			\prod_{k \in Q \setminus \{i\hspace{0.1pt}\}} c_k^*
    		\end{equation*}
    		\vspace{2pt}
    	\EndFor
    	\State
    		$\{x_i\}_{i \in J} \leftarrow
    		\mathsf{Zip}
    		\hspace{1pt}(
    			\hspace{1pt}
    			x_1^*,
    			\hspace{1pt}
    			\dots,
    			\hspace{1pt}
    			x_{t-1}^*
	    		;
    			\hspace{0.5pt}
    			J
    			\hspace{0.5pt}
    		)$
    		\vspace{6pt}
    	\State
    		Query $r_i \leftarrow
    		\mathcal{O}
    			_{\hspace{1pt}\mathbb{G}}
    			^{\hspace{1pt}\mathsf{dlog}}\hspace{1pt}(
    		\hspace{0pt}u_i\hspace{0pt}),
    		\ i \in J$
    		\hspace{38pt}// \textit{max $\hspace{2.5pt}t-1$ queries}
    		\vspace{8pt}
    	\State
    		Compute
    		\vspace{8pt}
    		\begin{equation*}
    			x_j \hspace{2pt}\leftarrow\hspace{2pt}
    			\frac{s_j - s_j^*}{c_j - c_j^*}
    			\hspace{2pt}
    			+
    			\hspace{2pt}
				\frac{1}{\mu_j} \sum_{i \in J}
				\hspace{2pt}
				\Big(
					\mu_i (s_i - r_i - c_i x_i) -
					\mu_i^* (s_i^* - r_i - c_i x_i)
				\Big)
    		\vspace{5pt}
    		\end{equation*}
		\State
			Set $z_0 \leftarrow x_j$
			\vspace{6pt}
		\State
			$(z_1, \dots, z_{t-1})
			\leftarrow \mathsf{Zip}^{-1}\hspace{1pt}(
				\{r_i\}_{i \in J}
			)$
			\vspace{6pt}
		\State
			\textbf{return $z_0, z_1, \dots, z_{t-1}$}
			\vspace{5pt}
    \end{algorithmic}
\end{algorithm}
\vspace{5pt}
\end{minipage}

\begin{rem}\label{rem_leaked_public_shares}
(\textit{Leaked public shares})
The adversary of Game \ref{orst_attack_impersonation}
is not given the public shares
$y_i = g ^ {x_i},\hspace{2pt} 1 \le i \le n,$
because these are not advertised.
However, a real-life attacker has probably
knowledge of these shares before mounting
its actual attack.
For example, a man-in-the middle who intercepts multiple
identification sessions can infer the public shares
from the captured proof packets in the form
\eqref{orst_leaked_public};
or, if the shareholders store the public shares
locally for, say, mutual verification purposes,
an attacker who compromises the device of a shareholder
can learn them immediately, if not erased.
Still, the proof of Theorem \ref{theorem_orst_security}
remains intact under this stronger assumption.
Note that, if the $y_i$'s must be given to $\mathcal{\bar{A}}$
in a simulated impersonation attack
(cf. steps 3-5, Algorithm \ref{alg_attack_simulator}),
these can be computed as
\vspace{5pt}
\begin{equation*}
\hspace{50pt}
y_k \leftarrow
\sqrt[\leftroot{0}\uproot{10}\lambda_k^k]{\hspace{1.5pt}y\hspace{1.5pt}
\Big(\hspace{1pt}\prod_{i \in J} y_i^{\lambda_i^k}\hspace{1pt}\Big)^{-1}},
\hspace{4pt} k \in \{1, \dots, n\} \setminus J\hspace{1pt},
\vspace{5pt}
\end{equation*}
where $y_i \equiv g ^ {x_i}$ and $\{\lambda_i^k\}_i$
are the interpolation coefficients for
$J \cup \{\hspace{0.5pt}k\hspace{0.5pt}\}$
(cf. Remark \ref{shamir_reconstruction}).
\end{rem}

\appendix

\section{Shamir's Secret Sharing}\label{section_shamir}

\noindent
We list for reference some basic facts regarding
the secret sharing scheme introduced by \cite{paper_shamir}.
Given a cyclic group $\mathbb{G} = \langle g \rangle$ of order $q$,
we denote by
$
\big(
	\hspace{0.3pt}
	\mathbb{Z}_q
	\hspace{0.3pt}
	\big)_{t-1}
	\hspace{0.3pt}
	[
		\hspace{0.5pt}
		X
		\hspace{0.5pt}
	]
$
the ring of polynomials of degree
at most $t-1$ over $\mathbb{Z}_q$.

\begin{defn}\label{shamir_definition}
The \textit{Shamir $(n, t)$-sharing scheme}, $1 \le t \le n < q$,
is the probabilistic algorithm
$(x_1, \dots, x_n;\hspace{2pt} y) \leftarrow D(x),
\hspace{2pt} x \in \mathbb{Z}_q$
defined as
\vspace{5pt}
\begin{equation*}
y \leftarrow g ^ x,
\ \ x_i \leftarrow f(x_i),
\ \ 1 \le i \le n,
\ \ f \leftarrow_\$ \big(
	\hspace{0.3pt}
	\mathbb{Z}_q
	\hspace{0.3pt}
	\big)_{t-1}
	\hspace{0.3pt}
	[
		\hspace{0.5pt}
		X
		\hspace{0.5pt}
	]
\textup{ with }
f(0) = x
\hspace{0pt}
\vspace{5pt}
\end{equation*}
The space of possible Shamir $(n,t)$-sharings of $x$
is denoted by
\vspace{5pt}
\begin{equation*}
D_x =\
\left\{(x_1, \dots, x_n;\hspace{2pt} y)
\hspace{4pt}
\middle\vert
\hspace{4pt}
(x_1, \dots, x_n;\hspace{2pt} y) \leftarrow D(x)
\right\}
\hspace{0pt}
\vspace{5pt}
\end{equation*}
\end{defn}

\begin{rem}\label{shamir_reconstruction}
(\textit{Reconstruction formula})
Given $(x_1, \dots, x_n;\hspace{2pt} y) \in D_x$,
the condition
\vspace{5pt}
\begin{equation}\label{shamir_threshold_condition}
x = \sum_{i \in Q} \lambda_i x_i
\iff
|Q| \ge t
\iff
y = \prod_{i \in Q} y_i^{\lambda_i},
\vspace{5pt}
\end{equation}
holds true,
where $\{\lambda_i\}_{i \in Q}$ are the
Lagrange interpolation coefficients for $Q$
and $y_i\equiv g ^ {x_i}$
are the public shares.
\end{rem}

%\begin{rem}\label{shamir_degrees_of_freedom}
%(\textit{$t - 1$ degrees of freedom})
%Given $J \subset \{1, \dots, n\}$ with $|J| = t - 1$,
%pick $x^*_i \in \mathbb{Z}_q,\hspace{2pt} i \in J$.
%Given $x \in \mathbb{Z}_q$, there is a unique
%$(x_1, \dots, x_n;\hspace{1pt} y) \in D_x$
%such that
%\vspace{5pt}
%\begin{equation*}
%x_i = x^*_i,\hspace{2pt}\forall i \in J
%\vspace{5pt}
%\end{equation*}
%\end{rem}

\begin{rem}\label{shamir_security}
(\textit{Security of Shamir's sharing})
Given $x,\hspace{2pt} x^* \in \mathbb{Z}_q$ and
$J \subset \{1, \dots, n\}$ with $|J| = t - 1$,
the probability distributions
\vspace{5pt}
\begin{equation*}
\{\{x_i\}_{i \in J}:
(x_1, \dots, x_n;\ y) \leftarrow D(x)\},
\hspace{8pt}
\{\{x_i\}_{i \in J}:
(x_1, \dots, x_n;\ y) \leftarrow D(x^*)\}
\vspace{5pt}
\end{equation*}
are indistinguishable.
\end{rem}

\section{Local Forking Lemma}\label{section_local_forking_lemma}

\noindent
The Forking Lemma was first introduced by
\cite{paper_pointcheval_stern_1}, \cite{paper_pointcheval_stern_2}
as part of the rewinding methodology for proving
the security of Fiat-Shamir based signature schemes
in the random oracle. It was later elaborated as
General Forking Lemma by \cite{paper_bellare_musig}, who
abstracted away the signature specific details.
The Local Forking Lemma is a variance
by \cite{paper_bellare_local_forking}
which dispenses with rewinding completely,
allowing to fork a process
by reprogramming the oracle at a single location
as opposed to every location after the fork.

Consider a deterministic algorithm of the form
\vspace{5pt}
\begin{equation}\label{local_forking_s_form}
\mathcal{S}: \Theta \times C^{\hspace{0.5pt}m} \rightarrow
\{\hspace{0.5pt}0, 1, \dots, m\hspace{0.5pt}\} \times T,
\ \ (
	\hspace{0.5pt}
	k,
	\tau
	\hspace{0.2pt}
)
\leftarrow
\mathcal{S}(
	\hspace{0.4pt}
	\theta
	\hspace{1pt}
	;
	\hspace{1pt}
	h_1,
	\dots,
	h_m
	\hspace{0.0pt}
),
\vspace{5pt}
\end{equation}
running internally a hash oracle
with tape $h_1, \dots, h_m$
(cf. Section \ref{section_hash_oracles}).
Think of $\theta$ as the random coins,
$k$ as the \textit{main} output and
$\tau$ as the \textit{side} output.
If $k \ge 1$, then the main output can be thought of as indicating
some peculiarity of the $k$-th distinct
oracle query regarding the side output,
while the case $k = 0$ is interpreted as failure.
We denote by
\vspace{6pt}
\begin{equation}\label{local_forking_acc}
\mathsf{acc}
	\hspace{0.3pt}
	(
		\hspace{0.3pt}
		\mathcal{S}
		\hspace{0.3pt}
	)
\hspace{1pt}
=
\hspace{1pt}
Pr\hspace{1pt}[\hspace{1pt}k \ge 1 :
\begin{Bmatrix}
\ (
	\hspace{0.4pt}
	k,
	\tau
	\hspace{0.2pt}
)
\leftarrow
\mathcal{S}
	\hspace{0.5pt}
	(
		\hspace{0.5pt}
		\theta
		\hspace{0.5pt}
		;
		\hspace{0.5pt}
		h_1,
		\dots,
		h_m
		\hspace{0.5pt}
	),
\ \ \theta \leftarrow_\$ \Theta\ \ \ \\[2pt]
h_\nu \leftarrow_\$ C,
\ \ 1 \le \nu \le m
\end{Bmatrix}
\hspace{1pt}]\\[6pt]
\end{equation}
the probability that $\mathcal{S}$ accepts
taken over the possible coins and oracle outputs.

\begin{defn}\label{def_local_fork}
The \textit{local fork of} $\mathcal{S}$ is
Algorithm \ref{alg_local_fork}.
\end{defn}

\noindent
That is, if $\mathcal{S}$ accepts, then
the fork reruns it with the same input except
for the $k$-th hash, which is
afresh uniformly sampled; otherwise it aborts.
When the second execution completes, the fork checks
whether $\mathcal{S}$ accepts again under the constraint
$h_k^* \neq h_k$ and returns both side outputs;
otherwise, it aborts. We denote by
\vspace{5pt}
\begin{equation}\label{local_forking_forkacc}
\mathsf{forkAcc}
\hspace{0.3pt}
(
	\hspace{0.3pt}
	\mathcal{S}
	\hspace{0.3pt}
)
\hspace{1pt}
=
\hspace{1pt}
Pr\hspace{1pt}[\hspace{1.5pt}b = 1 :
\hspace{2pt}(
	\hspace{0.5pt}
	b,
	\mathsf{out}
	\hspace{0.5pt}
)
\leftarrow
\mathsf{LocalFork}_{\mathcal{S}}
	\hspace{0.3pt}(
	\hspace{0.3pt}
	\theta
	\hspace{0.3pt}
),
\ \theta \leftarrow_\$ \Theta
\hspace{1.5pt}]\hspace{1pt}
\vspace{8pt}
\end{equation}
the probability that the local fork does not abort
taken over the possible random coins of $\mathcal{S}$.
The local forking lemma asserts the following lower bound.

\begin{lem}\label{local_forking_lemma}
% \hspace{-8pt}
\textup{(\textit{Local Forking Lemma}, \cite{paper_bellare_local_forking})}
For every deterministic algorithm $\mathcal{S}$ as in
\eqref{local_forking_s_form} issuing $m$ distinct queries
to a hash oracle with tape
$[\hspace{0.75pt}h_1, \dots, h_{m}\hspace{0.75pt}]$,
\vspace{5pt}
\begin{equation}\label{local_forking_bound}
\mathsf{forkAcc}
	(
		\mathcal{S}
	)
	\hspace{2pt}
	\ge
	\hspace{2pt}
	\frac{1}{\hspace{2pt}m\hspace{2pt}}
	\hspace{2pt}
	\mathsf{acc}
	\hspace{0.3pt}
	(
		\hspace{0.3pt}
		\mathcal{S}
		\hspace{0.3pt}
	) ^ {\hspace{1pt}2}
\vspace{5pt}
\end{equation}
\end{lem}

\begin{minipage}{0.96\textwidth}
\vspace{-5pt}
\begin{algorithm}[H]
  	\captionsetup{labelfont={sc,bf}}
	\caption{$\textsf{LocalFork}_{\mathcal{S}}(\hspace{0.5pt}\theta\hspace{0.5pt})$}\label{alg_local_fork}
  \begin{algorithmic}[1]
  	\vspace{2pt}
			\State
				$h_\nu \leftarrow_\$ C,
				\ \ 1 \le \nu\le m$
				\vspace{4pt}
			\State
				$(
					\hspace{0.5pt}
					k,
					\tau
					\hspace{0.2pt}
				)
				\leftarrow
				\mathcal{S}
				\hspace{0.3pt}
				(
					\hspace{0.3pt}
					\theta
					\hspace{0.3pt};
					\hspace{0.3pt} h_1,
					\dots,
					h_m
				)$
				\vspace{4pt}
			\If{$k = 0$}\vspace{2pt}
    			\State
    				\textbf{return
    					$(
    						\hspace{1pt}
    						0,
    						\bot
    						\hspace{1pt}
    					)
    					$
    				}\vspace{0pt}
			\EndIf
			\State
				$h_k^* \leftarrow_\$ C$
				\vspace{6pt}
			\State
				$(k^*, \tau^*) \leftarrow
				\mathcal{S}
					\hspace{1pt}
					(
						\hspace{0.5pt}
						\theta
						\hspace{1.5pt}
					;
					\hspace{1pt}h_1,
					\dots,
					h_{k-1},
					\hspace{1pt}h_k^*,
					\hspace{1pt} h_{k+1},
					\dots
					h_m
				)$
				\vspace{6pt}
			\If{$k^* = k\ \land\ h_k \neq h_k^*$}\vspace{3pt}
				\State
					\textbf{return
						$(
							\hspace{1pt}
							1,
							(
								\hspace{0.5pt}
								\tau,
								\tau^*
							)
							\hspace{1pt})
						$}
					\vspace{2pt}
			\EndIf
			\State
				\textbf{return
					$(
						\hspace{1pt}
						0,
						\bot
						\hspace{1pt}
					)$
				}
  \end{algorithmic}
\end{algorithm}
\vspace{0pt}
\end{minipage}

\bibliographystyle{plain}
\bibliography{refs}

\end{document}

